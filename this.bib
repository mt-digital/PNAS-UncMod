

@article{Laland2004,
  author =        {Laland, Kevin N},
  journal =       {Learning and Behavior},
  number =        {1},
  pages =         {4--14},
  title =         {{Social Learning Strategies}},
  volume =        {32},
  year =          {2004},
}

@book{BoydRicherson1985,
  address =       {Chicago},
  author =        {Boyd, Robert and Richerson, Peter J.},
  publisher =     {University of Chicago Press},
  title =         {{Culture and the evolutionary process}},
  year =          {1985},
}

@article{Henrich1998,
  author =        {Henrich, Joe and Boyd, Robert},
  journal =       {Evolution and Human Behavior},
  number =        {4},
  pages =         {215--241},
  title =         {{The Evolution of Conformist Transmission and the
                   Emergence of Between-Group Differences}},
  volume =        {19},
  year =          {1998},
  abstract =      {Unlike other animal species, much of the variation
                   among human groups is cultural: genetically similar
                   people living in similar environments exhibit
                   strikingly different patterns of behavior because
                   they have different, culturally acquired beliefs and
                   values. Such cultural transmission is based on
                   complex, derived psychological mechanisms that are
                   likely to have been shaped by natural selection. It
                   is important to understand the nature of these
                   evolved psychological mechanisms because they
                   determine which beliefs and values spread and persist
                   in human groups. Boyd and Richerson showed that a
                   tendency to acquire the most common behavior
                   exhibited in a society was adaptive in a simple model
                   of evolution in a spatially varying environment,
                   because such a tendency increases the probability of
                   acquiring adaptive beliefs and values. Here, we study
                   the evolution of such "conformist transmission" in a
                   more general model in which environments vary in both
                   time and space. The analysis of this model indicates
                   that conformist transmission is favored under a very
                   broad range of conditions, broader in fact than the
                   range of conditions that favor a substantial reliance
                   on social learning. The analysis also suggests that
                   there is a synergistic relationship between the
                   evolution of imitation and the evolution of
                   conformism. We conclude by examining the role of
                   conformism in explaining the maintenance of cultural
                   differences among groups. {\textcopyright} 1998
                   Elsevier Science Inc.},
  doi =           {10.1016/S1090-5138(98)00018-X},
  issn =          {10905138},
}

@article{Rogers1988,
  author =        {Rogers, Alan R},
  journal =       {American Anthropologist},
  number =        {4},
  pages =         {819--831},
  title =         {{Does biology constrain culture?}},
  volume =        {90},
  year =          {1988},
  abstract =      {Methods This article will evaluate the premises of
                   the two arguments above, a much easier task than
                   evaluating the truth of their conclusions. This task
                   is especially easy because these premises
                   (propositions 1.1 and 2.1) have been advanced, not as
                   peculiar features of ... \n},
  doi =           {10.1525/aa.1988.90.4.02a00030},
  isbn =          {9788599141038},
  issn =          {0002-7294},
}

@article{Feldman1996,
  author =        {Feldman, Marcus W. and Aoki, Kenichi and
                   Kumm, Jochen},
  journal =       {Anthropological Science},
  number =        {3},
  pages =         {209--232},
  title =         {{Individual versus social learning: evolutionary
                   analysis in a fluctuating environment}},
  volume =        {104},
  year =          {1996},
}

@article{McElreath2005,
  author =        {McElreath, Richard and Lubell, Mark and
                   Richerson, Peter J. and Waring, Timothy M. and
                   Baum, William and Edsten, Edward and
                   Efferson, Charles and Paciotti, Brian},
  journal =       {Evolution and Human Behavior},
  number =        {6},
  pages =         {483--508},
  title =         {{Applying evolutionary models to the laboratory study
                   of social learning}},
  volume =        {26},
  year =          {2005},
  abstract =      {Cultural evolution is driven, in part, by the
                   strategies that individuals employ to acquire
                   behavior from others. These strategies themselves are
                   partly products of natural selection, making the
                   study of social learning an inherently Darwinian
                   project. Formal models of the evolution of social
                   learning suggest that reliance on social learning
                   should increase with task difficulty and decrease
                   with the probability of environmental change. These
                   models also make predictions about how individuals
                   integrate information from multiple peers. We present
                   the results of microsociety experiments designed to
                   evaluate these predictions. The first experiment
                   measures baseline individual learning strategy in a
                   two-armed bandit environment with variation in task
                   difficulty and temporal fluctuation in the payoffs of
                   the options. Our second experiment addresses how
                   people in the same environment use minimal social
                   information from a single peer. Our third experiment
                   expands on the second by allowing access to the
                   behavior of several other individuals, permitting
                   frequency-dependent strategies like conformity. In
                   each of these experiments, we vary task difficulty
                   and environmental fluctuation. We present several
                   candidate strategies and compute the expected payoffs
                   to each in our experimental environment. We then fit
                   to the data the different models of the use of social
                   information and identify the best-fitting model via
                   model comparison techniques. We find substantial
                   evidence of both conformist and nonconformist social
                   learning and compare our results to theoretical
                   expectations. {\textcopyright} 2005 Elsevier Inc. All
                   rights reserved.},
  doi =           {10.1016/j.evolhumbehav.2005.04.003},
  issn =          {10905138},
}

@article{Kendal2018,
  author =        {Kendal, Rachel L. and Boogert, Neeltje J. and
                   Rendell, Luke and Laland, Kevin N. and Webster, Mike and
                   Jones, Patricia L.},
  journal =       {Trends in Cognitive Sciences},
  number =        {7},
  pages =         {651--665},
  publisher =     {Elsevier Ltd},
  title =         {{Social Learning Strategies: Bridge-Building between
                   Fields}},
  volume =        {22},
  year =          {2018},
  abstract =      {While social learning is widespread, indiscriminate
                   copying of others is rarely beneficial. Theory
                   suggests that individuals should be selective in
                   what, when, and whom they copy, by following 'social
                   learning strategies' (SLSs). The SLS concept has
                   stimulated extensive experimental work, integrated
                   theory, and empirical findings, and created impetus
                   to the social learning and cultural evolution fields.
                   However, the SLS concept needs updating to
                   accommodate recent findings that individuals switch
                   between strategies flexibly, that multiple strategies
                   are deployed simultaneously, and that there is no
                   one-to-one correspondence between psychological
                   heuristics deployed and resulting population-level
                   patterns. The field would also benefit from the
                   simultaneous study of mechanism and function. SLSs
                   provide a useful vehicle for bridge-building between
                   cognitive psychology, neuroscience, and evolutionary
                   biology.},
  doi =           {10.1016/j.tics.2018.04.003},
  issn =          {1879307X},
}

@article{Allen2019,
  author =        {Allen, Jenny A.},
  journal =       {BioEssays},
  number =        {11},
  pages =         {1--8},
  title =         {{Community through Culture: From Insects to Whales:
                   How Social Learning and Culture Manifest across
                   Diverse Animal Communities}},
  volume =        {41},
  year =          {2019},
  abstract =      {It has become increasingly clear that social learning
                   and culture occur much more broadly, and in a wider
                   variety of animal communities, than initially
                   believed. Recent research has expanded the list to
                   include insects, fishes, elephants, and cetaceans.
                   Such diversity allows scientists to expand the scope
                   of potential research questions, which can help form
                   a more complete understanding of animal culture than
                   any single species can provide on its own. It is
                   crucial to understand how culture and social learning
                   present in different communities, as well as what
                   influences community structure and culture may have
                   on one another, so that the results across these
                   different studies may most effectively inform one
                   another. This review presents an overview of social
                   learning in species across a spectrum of community
                   structures, providing the necessary infrastructure to
                   allow a comparison of studies that will help move the
                   field of animal culture forward.},
  doi =           {10.1002/bies.201900060},
  issn =          {15211878},
}

@article{Heyes2016,
  author =        {Heyes, Cecilia},
  journal =       {Philosophical Transactions of the Royal Society B:
                   Biological Sciences},
  number =        {1693},
  title =         {{Blackboxing: Social learning strategies and cultural
                   evolution}},
  volume =        {371},
  year =          {2016},
  abstract =      {Social learning strategies (SLSs) enable humans,
                   non-human animals, and artificial agents to make
                   adaptive decisions about when they should copy other
                   agents, and who they should copy. Behavioural
                   ecologists and economists have discovered an
                   impressive range of SLSs, and explored their likely
                   impact on behavioural efficiency and reproductive
                   fitness while using the ‘phenotypic gambit';
                   ignoring, or remaining deliberately agnostic about,
                   the nature and origins of the cognitive processes
                   that implement SLSs. Here I argue that this
                   ‘blackboxing' of SLSs is no longer a viable
                   scientific strategy. It has contributed, through the
                   ‘social learning strategies tournament', to the
                   premature conclusion that social learning is
                   generally better than asocial learning, and to a deep
                   puzzle about the relationship between SLSs and
                   cultural evolution. The puzzle can be solved by
                   recognizing that whereas most SLSs are
                   ‘planetary'—they depend on domain-general
                   cognitive processes—some SLSs, found only in
                   humans, are ‘cook-like'—they depend on explicit,
                   metacognitive rules, such as copy digital natives.
                   These metacognitive SLSs contribute to cultural
                   evolution by fostering the development of processes
                   that enhance the exclusivity, specificity, and
                   accuracy of social learning.},
  doi =           {10.1098/rstb.2015.0369},
  issn =          {14712970},
}

@article{Vul2014,
  author =        {Vul, Edward and Goodman, Noah and
                   Griffiths, Thomas L. and Tenenbaum, Joshua B.},
  journal =       {Cognitive Science},
  number =        {4},
  pages =         {599--637},
  title =         {{One and done? Optimal decisions from very few
                   samples}},
  volume =        {38},
  year =          {2014},
  abstract =      {In many learning or inference tasks human behavior
                   approximates that of a Bayesian ideal observer,
                   suggesting that, at some level, cognition can be
                   described as Bayesian inference. However, a number of
                   findings have highlighted an intriguing mismatch
                   between human behavior and standard assumptions about
                   optimality: People often appear to make decisions
                   based on just one or a few samples from the
                   appropriate posterior probability distribution,
                   rather than using the full distribution. Although
                   sampling-based approximations are a common way to
                   implement Bayesian inference, the very limited
                   numbers of samples often used by humans seem
                   insufficient to approximate the required probability
                   distributions very accurately. Here, we consider this
                   discrepancy in the broader framework of statistical
                   decision theory, and ask: If people are making
                   decisions based on samples-but as samples are
                   costly-how many samples should people use to optimize
                   their total expected or worst-case reward over a
                   large number of decisions? We find that under
                   reasonable assumptions about the time costs of
                   sampling, making many quick but locally suboptimal
                   decisions based on very few samples may be the
                   globally optimal strategy over long periods. These
                   results help to reconcile a large body of work
                   showing sampling-based or probability matching
                   behavior with the hypothesis that human cognition can
                   be understood in Bayesian terms, and they suggest
                   promising future directions for studies of
                   resource-constrained cognition. {\textcopyright} 2014
                   Cognitive Science Society, Inc.},
  doi =           {10.1111/cogs.12101},
  issn =          {03640213},
}

@article{Gershman2019,
  author =        {Gershman, Samuel J.},
  journal =       {Decision},
  number =        {3},
  pages =         {277--286},
  title =         {{Uncertainty and exploration}},
  volume =        {6},
  year =          {2019},
  abstract =      {In order to discover the most rewarding actions,
                   agents must collect information about their
                   environment, potentially foregoing reward. The
                   optimal solution to this "explore- exploit" dilemma
                   is often computationally challenging, but principled
                   algorithmic approximations exist. These
                   approximations utilize uncertainty about action
                   values in different ways. Some random exploration
                   algorithms scale the level of choice stochasticity
                   with the level of uncertainty. Other directed
                   exploration algorithms add a "bonus" to action values
                   with high uncertainty. Random exploration algorithms
                   are sensitive to total uncertainty across actions,
                   whereas directed exploration algorithms are sensitive
                   to relative uncertainty. This article reports a
                   multiarmed bandit experiment in which total and
                   relative uncertainty were orthogonally manipulated.
                   We found that humans employ both exploration
                   strategies, and that these strategies are
                   independently controlled by different uncertainty
                   computations.},
  doi =           {10.1037/dec0000101},
  issn =          {23259973},
}

@article{Schulz2019,
  author =        {Schulz, Eric and Gershman, Samuel J.},
  journal =       {Current Opinion in Neurobiology},
  pages =         {7--14},
  publisher =     {Elsevier Ltd},
  title =         {{The algorithmic architecture of exploration in the
                   human brain}},
  volume =        {55},
  year =          {2019},
  abstract =      {Balancing exploration and exploitation is one of the
                   central problems in reinforcement learning. We review
                   recent studies that have identified multiple
                   algorithmic strategies underlying exploration. In
                   particular, humans use a combination of random and
                   uncertainty-directed exploration strategies, which
                   rely on different brain systems, have different
                   developmental trajectories, and are sensitive to
                   different task manipulations. Humans are also able to
                   exploit sophisticated structural knowledge to aid
                   their exploration, such as information about
                   correlations between options. New computational
                   models, drawing inspiration from machine learning,
                   have begun to formalize these ideas and offer new
                   ways to understand the neural basis of reinforcement
                   learning.},
  doi =           {10.1016/j.conb.2018.11.003},
  issn =          {18736882},
}

@article{Moya2020,
  author =        {Moya, Cristina and {Cruz y Celis Peniche}, Patricio and
                   Kline, Michelle A. and Smaldino, Paul E.},
  journal =       {American Journal of Human Biology},
  number =        {5},
  pages =         {1--8},
  title =         {{Dynamics of behavior change in the COVID world}},
  volume =        {32},
  year =          {2020},
  doi =           {10.1002/ajhb.23485},
  issn =          {15206300},
}

@article{Jones2021,
  author =        {Jones, James Holland and Ready, Elspeth and
                   Pisor, Anne C.},
  journal =       {American Journal of Human Biology},
  number =        {4},
  pages =         {1--17},
  title =         {{Want climate-change adaptation? Evolutionary theory
                   can help}},
  volume =        {33},
  year =          {2021},
  abstract =      {The idea of adaptation, in which an organism or
                   population becomes better suited to its environment,
                   is used in a variety of disciplines. Originating in
                   evolutionary biology, adaptation has been a central
                   theme in biological anthropology and human ecology.
                   More recently, the study of adaptation in the context
                   of climate change has become an important topic of
                   research in the social sciences. While there are
                   clearly commonalities in the different uses of the
                   concept of adaptation in these fields, there are also
                   substantial differences. We describe these
                   differences and suggest that the study of
                   climate-change adaptation could benefit from a
                   re-integration with biological and evolutionary
                   conceptions of human adaptation. This integration
                   would allow us to employ the substantial theoretical
                   tools of evolutionary biology and anthropology to
                   understand what promotes or impedes adaptation. The
                   evolutionary perspective on adaptation focuses on
                   diversity because diversity drives adaptive
                   evolution. Population structures are also critical in
                   facilitating or preventing adaptation to local
                   environmental conditions. This suggests that
                   climate-change adaptation should focus on the sources
                   of innovation and social structures that nurture
                   innovations and allow them to spread. Truly
                   innovative ideas are likely to arise on the periphery
                   of cohesive social groups and spread inward. The
                   evolutionary perspective also suggests that we pay
                   careful attention to correlated traits, which can
                   distort adaptive trajectories, as well as to the
                   importance of risk management in adaptations to
                   variable or uncertain environments. Finally, we
                   suggest that climate-change adaptation could benefit
                   from a broader study of how local groups adapt to
                   their dynamic environments, a process we call
                   “autochthonous adaptation.”.},
  doi =           {10.1002/ajhb.23539},
  issn =          {15206300},
}

@article{NatureEnergyEditorialPromisesPremises2018,
  author =        {Editorial},
  journal =       {Nature Energy},
  number =        {1},
  pages =         {1},
  title =         {{Promises and premises}},
  volume =        {3},
  year =          {2018},
  doi =           {10.1038/s41560-017-0083-y},
  issn =          {20587546},
}

@article{Brisbois2022,
  author =        {Brisbois, Marie Claire},
  journal =       {Nature},
  number =        {3 March 2022},
  title =         {{Innovation in the future can't slash emissions now}},
  volume =        {603},
  year =          {2022},
  doi =           {10.4135/9781412971959.n413},
  issn =          {17401267},
}

@article{Enquist2007,
  author =        {Enquist, Magnus and Eriksson, Kimmo and
                   Ghirlanda, Stefano},
  journal =       {American Anthropologist},
  number =        {4},
  pages =         {727--734},
  title =         {{Critical Social Learning: A Solution to Rogers's
                   Paradox of Nonadaptive Culture}},
  volume =        {109},
  year =          {2007},
  abstract =      {Alan Rogers (1988) presented a game theory model of
                   the evolution of social learning, yielding the
                   paradoxical conclusion that social learning does not
                   increase the fitness of a population. We expand on
                   this model, allowing for imperfections in individual
                   and social learning as well as incorporating a
                   “critical social learning” strategy that tries to
                   solve an adaptive problem first by social learning,
                   and then by individual learning if socially acquired
                   behavior proves unsatisfactory. This strategy always
                   proves superior to pure social learning and typically
                   has higher fitness than pure individual learning,
                   providing a solution to Rogers's paradox of
                   nonadaptive culture. Critical social learning is an
                   evolutionarily stable strategy (ESS) unless cultural
                   transmission is highly unfaithful, the environment is
                   highly variable, or social learning is much more
                   costly than individual learning. We compare the model
                   to empirical data on social learning and on spatial
                   variation in primate cultures and list three
                   requirements for adaptive culture.},
  doi =           {10.1525/aa.2007.109.4.727},
  issn =          {0002-7294},
}

@article{Rendell2010,
  author =        {Rendell, L. and Boyd, R. and Cownden, D. and
                   Enquist, M. and Eriksson, K. and Feldman, M. W. and
                   Fogarty, L. and Ghirlanda, S. and Lillicrap, T. and
                   Laland, K. N.},
  journal =       {Science},
  number =        {5975},
  pages =         {208--213},
  title =         {{Why copy others? insights from the social learning
                   strategies tournament}},
  volume =        {328},
  year =          {2010},
  abstract =      {Social learning (learning through observation or
                   interaction with other individuals) is widespread in
                   nature and is central to the remarkable success of
                   humanity, yet it remains unclear why copying is
                   profitable and how to copy most effectively. To
                   address these questions, we organized a computer
                   tournament in which entrants submitted strategies
                   specifying how to use social learning and its asocial
                   alternative (for example, trial-andor learning) to
                   acquire adaptive behavior in a complex environment.
                   Most current theory predicts the emergence of mixed
                   strategies that rely on some combination of the two
                   types of learning. In the tournament, however,
                   strategies that relied heavily on social learning
                   were found to be remarkably successful, even when
                   asocial information was no more costly than social
                   information. Social learning proved advantageous
                   because individuals frequently demonstrated the
                   highest-payoff behavior in their repertoire,
                   inadvertently filtering information for copiers. The
                   winning strategy (discountmachine) relied nearly
                   exclusively on social learnina and weiahted
                   information accordina to the time since acauisition.},
  doi =           {10.1126/science.1184719},
  issn =          {00368075},
}

@article{Baracchi2018,
  author =        {Baracchi, David and Vasas, Vera and
                   {Jamshed Iqbal}, Soha and Alem, Sylvain},
  journal =       {Behavioral Ecology},
  number =        {1},
  pages =         {186--192},
  title =         {{Foraging bumblebees use social cues more when the
                   task is difficult}},
  volume =        {29},
  year =          {2018},
  abstract =      {When foraging in their natural environment, many
                   animals readily complement their personal knowledge
                   with additional social information. To balance the
                   costs and benefits of copying others, animals have to
                   discern situations in which it is more advantageous
                   to use social rather than personal information. Here,
                   we used foraging bumblebees (Bombus terrestris) in a
                   controlled laboratory setting and showed that the
                   difficulty of a foraging task affects how the bees
                   weight the 2 types of information. We used artificial
                   flowers to devise easy and difficult discriminatory
                   tasks, and tested the influence of floral and social
                   cues on decision making. When facing an easy
                   discrimination task, foraging bees were likely to
                   rely on personal information and were only marginally
                   affected by social information. By contrast, they
                   prioritized social over personal information when
                   flower discrimination was difficult and therefore the
                   probability of making errors was higher. In summary,
                   bees are able to use social and personal information
                   to optimize foraging decisions in a flexible way.},
  doi =           {10.1093/beheco/arx143},
  issn =          {14657279},
}

@article{Aplin2017,
  author =        {Aplin, Lucy M. and Sheldon, Ben C. and
                   McElreath, Richard},
  journal =       {Proceedings of the National Academy of Sciences of
                   the United States of America},
  number =        {30},
  pages =         {7830--7837},
  title =         {{Conformity does not perpetuate suboptimal traditions
                   in a wild population of songbirds}},
  volume =        {114},
  year =          {2017},
  abstract =      {Social learning is important to the life history of
                   many animals, helping individuals to acquire new
                   adaptive behavior. However despite long-running
                   debate, it remains an open question whether a
                   reliance on social learning can also lead to
                   mismatched or maladaptive behavior. In a previous
                   study, we experimentally induced traditions for
                   opening a bidirectional door puzzle box in replicate
                   subpopulations of the great tit Parus major.
                   Individuals were conformist social learners,
                   resulting in stable cultural behaviors. Here, we vary
                   the rewards gained by these techniques to ask to what
                   extent established behaviors are flexible to changing
                   conditions. When subpopulations with established
                   foraging traditions for one technique were subjected
                   to a reduced foraging payoff, 49% of birds switched
                   their behavior to a higher-payoff foraging technique
                   after only 14 days, with younger individuals showing
                   a faster rate of change. We elucidated the
                   decision-making process for each individual, using a
                   mechanistic learning model to demonstrate that,
                   perhaps surprisingly, this population-level change
                   was achieved without significant asocial exploration
                   and without any evidence for payoff-biased copying.
                   Rather, by combining conformist social learning with
                   payoff-sensitive individual reinforcement (updating
                   of experience), individuals and populations could
                   both acquire adaptive behavior and track
                   environmental change.},
  doi =           {10.1073/pnas.1621067114},
  isbn =          {1621067114},
  issn =          {10916490},
}

@article{Toyokawa2019,
  author =        {Toyokawa, Wataru and Whalen, Andrew and
                   Laland, Kevin N},
  journal =       {Nature Human Behaviour},
  publisher =     {Springer US},
  title =         {{Social learning strategies regulate the wisdom and
                   madness of interactive crowds}},
  year =          {2019},
  abstract =      {Why groups of individuals sometimes exhibit
                   collective 'wisdom' and other times maladaptive
                   'herding' is an enduring conundrum. Here we show that
                   this conflict is regulated by the social learning
                   strategies deployed. We examined the patterns of
                   human social learning through an interactive online
                   experiment with 699 participants, varying both task
                   uncertainty and group size, then used hierarchical
                   Bayesian model-fitting to identify the individual
                   learning strategies exhibited by participants.
                   Challenging tasks elicit greater conformity amongst
                   individuals, with rates of copying increasing with
                   group size, leading to high probabilities of
                   maladaptive herding amongst large groups confronted
                   with uncertainty. Conversely, the reduced social
                   learning of small groups, and the greater probability
                   that social information would be accurate for
                   less-challenging tasks, generated 'wisdom of the
                   crowd' effects in other circumstances. Our
                   model-based approach provides novel evidence that the
                   likelihood of swarm intelligence versus herding can
                   be predicted, resolving a longstanding puzzle in the
                   literature.},
  doi =           {10.1101/326637},
  isbn =          {4156201805},
  issn =          {2397-3374},
  url =           {https://www.biorxiv.org/content/early/2018/06/19/326637},
}

@article{Leris2016,
  author =        {Leris, Ioannis and Reader, Simon M.},
  journal =       {Animal Behaviour},
  pages =         {11--19},
  publisher =     {Elsevier Ltd},
  title =         {{Age and early social environment influence guppy
                   social learning propensities}},
  volume =        {120},
  year =          {2016},
  abstract =      {Social learning, learning from others, allows animals
                   to quickly and adaptively adjust to changing
                   environments, but only if social learning provides
                   reliable, useful information in that environment.
                   Early life conditions provide a potential cue to the
                   reliability of social information later in life.
                   Here, we addressed whether direct early life
                   experience of the utility of social learning
                   influences later social learning propensities. We
                   reared guppy, Poecilia reticulata, fry for 45 days in
                   three different social conditions which involved the
                   presence of adult demonstrators providing cues about
                   feeding locations in the tanks (‘follow adults' and
                   ‘avoid adults' treatments), or their absence (‘no
                   adults' treatment). In the ‘follow adults'
                   treatment, juveniles that swam in the same direction
                   as the adult demonstrators found food, whereas in the
                   ‘avoid adults' treatment, subjects that swam in the
                   opposite direction to the demonstrators found food.
                   We then tested the fish with a social learning task,
                   to examine whether prior experience had influenced
                   the social learning tendencies of the juveniles.
                   After another 45 days of rearing under common-garden
                   conditions with no adult fish present in the tanks,
                   subjects were retested with the same social learning
                   task, to investigate whether early experiences had
                   effects persisting into adulthood. After 45 days of
                   rearing we found no evidence for social learning in
                   any of the experimental groups. However, after 90
                   days of rearing, we found evidence of social
                   learning, but only in the ‘follow adults'
                   treatment. These results suggest that social learning
                   propensities may develop over life, and that prior
                   exposure to conspecifics providing useful foraging
                   information during early life can shape the degree of
                   reliance on social learning in adulthood.},
  doi =           {10.1016/j.anbehav.2016.07.012},
  issn =          {00033472},
  url =           {http://dx.doi.org/10.1016/j.anbehav.2016.07.012},
}

@article{Avargues-Weber2018,
  author =        {Avargu{\`{e}}s-Weber, Aurore and Lachlan, Robert and
                   Chittka, Lars},
  journal =       {Animal Behaviour},
  pages =         {209--214},
  title =         {{Bumblebee social learning can lead to suboptimal
                   foraging choices}},
  volume =        {135},
  year =          {2018},
  abstract =      {Bumblebees are influenced by socially acquired
                   information when deciding on which flowers to forage.
                   In some circumstances, however, this attraction
                   towards conspecifics may lead to suboptimal foraging
                   performance because the presence of multiple
                   pollinators typically results in a faster rate of
                   nectar depletion in the flower. We tested the
                   capacity of bees to learn to avoid flowers occupied
                   by conspecifics when they offered a lower reward than
                   unoccupied similar flowers. Bumblebees were able to
                   discriminate between poorly and highly rewarding
                   flowers by using the presence of a nonsocial cue (a
                   wooden rectangular white block). When poorly
                   rewarding flowers were indicated by social cues
                   (model bees), however, bees did not discriminate
                   between the two flower types except when an
                   additional cue was provided (flower colour). These
                   findings indicate that bumblebees attach particular
                   meaning to conspecific presence on flowers, even when
                   this could lead to suboptimal foraging performance.
                   The relatively lower flexibility in the use of social
                   than nonsocial cues suggests a biased positive value
                   of conspecifics as indicators of rewarded flowers.},
  doi =           {10.1016/j.anbehav.2017.11.022},
  issn =          {00033472},
}

@book{SuttonBartoBook,
  address =       {Cambridge, MA},
  author =        {Sutton, Richard S and Barto, Andrew G},
  edition =       {2nd},
  publisher =     {MIT Press},
  title =         {{Reinforcement Learning : An Introduction}},
  year =          {2018},
}

@article{Bezanson2017,
  author =        {Bezanson, Jeff and Edelman, Alan and
                   Karpinski, Stefan and Shah, Viral B.},
  journal =       {SIAM Review},
  number =        {1},
  pages =         {65--98},
  title =         {{Julia: A fresh approach to numerical computing}},
  volume =        {59},
  year =          {2017},
  abstract =      {Bridging cultures that have often been distant, Julia
                   combines expertise from the diverse helds of computer
                   science and computational science to create a new
                   approach to numerical computing. Julia is designed to
                   be easy and fast and questions notions generally held
                   to be "laws of nature" by practitioners of numerical
                   computing: 1. High-level dynamic programs have to be
                   slow. 2. One must prototype in one language and then
                   rewrite in another language for speed or deployment.
                   3. There are parts of a system appropriate for the
                   programmer, and other parts that are best left
                   untouched as they have been built by the experts. We
                   introduce the Julia programming language and its
                   design-a dance between specialization and
                   abstraction. Specialization allows for custom
                   treatment. Multiple dispatch, a technique from
                   computer science, picks the right algorithm for the
                   right circumstance. Abstraction, which is what good
                   computation is really about, recognizes what remains
                   the same after differences are stripped away.
                   Abstractions in mathematics are captured as code
                   through another technique from computer science,
                   generic programming. Julia shows that one can achieve
                   machine performance without sacrificing human
                   convenience.},
  doi =           {10.1137/141000671},
  issn =          {00361445},
}

@article{Datseris2022,
  author =        {Datseris, George and Vahdati, Ali R. and
                   DuBois, Timothy C.},
  journal =       {Simulation},
  pages =         {1--13},
  title =         {{Agents.jl: A performant and feature-full agent based
                   modelling software of minimal code complexity}},
  year =          {2022},
  abstract =      {Agent-based modeling is a simulation method in which
                   autonomous agents interact with their environment and
                   one another, given a predefined set of rules. It is
                   an integral method for modeling and simulating
                   complex systems, such as socio-economic problems.
                   Since agent-based models are not described by simple
                   and concise mathematical equations, the code that
                   generates them is typically complicated, large, and
                   slow. Here we present Agents.jl, a Julia-based
                   software that provides an ABM analysis platform with
                   minimal code complexity. We compare our software with
                   some of the most popular ABM software in other
                   programming languages. We find that Agents.jl is not
                   only the most performant but also the least
                   complicated software, providing the same (and
                   sometimes more) features as the competitors with less
                   input required from the user. Agents.jl also
                   integrates excellently with the entire Julia
                   ecosystem, including interactive applications,
                   differential equations, parameter optimization, and
                   so on. This removes any “extensions library”
                   requirement from Agents.jl, which is paramount in
                   many other tools.},
  doi =           {10.1177/00375497211068820},
  issn =          {17413133},
}

@article{Muthukrishna2016a,
  author =        {Muthukrishna, Michael and Morgan, Thomas J.H. and
                   Henrich, Joseph},
  journal =       {Evolution and Human Behavior},
  number =        {1},
  pages =         {10--20},
  publisher =     {Elsevier Inc.},
  title =         {{The when and who of social learning and conformist
                   transmission}},
  volume =        {37},
  year =          {2016},
  abstract =      {Formal evolutionary models predict when individuals
                   rely on social learning over individual learning and
                   the relative strength of their conformist social
                   learning biases. Here we use both treatment effects
                   and individual variation to test predictions about
                   the impact of (1) the number of traits in an
                   environment, (2) the adaptive or payoff relevance of
                   those traits, (3) the fidelity of transmission, and
                   (4) the size of groups. We find that both social
                   learning and the strength of conformist transmission
                   increase with the number of traits, the adaptive
                   value of those traits, and the fidelity of
                   transmission. The strength of conformist transmission
                   increases with group size, but only when there were 2
                   traits in the environment. Using individual-level
                   variation and recognizing that treatment effects
                   predictably impact individuals differently, we show
                   that IQ negatively predicts social learning, but has
                   a U-shaped relationship to conformist transmission,
                   suggesting strategic use of conformist-biased social
                   learning among those with the highest IQ. Other
                   plausible predictors, such as status, cultural
                   background, and personality, were not predictive.
                   Broadly, our results reveal that not only is the
                   conformist transmission bias ubiquitous, but that
                   past experiments, both human and non-human, have
                   likely underestimated its prevalence and the
                   prevalence of social learning by restricting designs
                   to only 2 traits.},
  doi =           {10.1016/j.evolhumbehav.2015.05.004},
  issn =          {10905138},
}

@article{Smaldino2018b,
  author =        {Smaldino, Paul E. and Aplin, Lucy M. and
                   Farine, Damien R.},
  journal =       {Scientific Reports},
  number =        {1},
  pages =         {1--10},
  title =         {{Sigmoidal Acquisition Curves Are Good Indicators of
                   Conformist Transmission}},
  volume =        {8},
  year =          {2018},
  doi =           {10.1038/s41598-018-30248-5},
  issn =          {20452322},
}

@article{Katsnelson2014,
  author =        {Katsnelson, Edith and Lotem, Arnon and
                   Feldman, Marcus W.},
  journal =       {Evolution},
  number =        {7},
  pages =         {1894--1906},
  title =         {{Assortative social learning and its implications for
                   human (and animal?) societies}},
  volume =        {68},
  year =          {2014},
  abstract =      {Choosing from whom to learn is an important element
                   of social learning. It affects learner success and
                   the profile of behaviors in the population. Because
                   individuals often differ in their traits and
                   capabilities, their benefits from different behaviors
                   may also vary. Homophily, or assortment, the tendency
                   of individuals to interact with other individuals
                   with similar traits, is known to affect the spread of
                   behaviors in humans. We introduce models to study the
                   evolution of assortative social learning (ASL), where
                   assorting on a trait acts as an individual-specific
                   mechanism for filtering relevant models from which to
                   learn when that trait varies. We show that when the
                   trait is polymorphic, ASL may maintain a stable
                   behavioral polymorphism within a population
                   (independently of coexistence with individual
                   learning in a population). We explore the evolution
                   of ASL when assortment is based on a nonheritable or
                   partially heritable trait, and when ASL competes with
                   different non-ASL strategies: oblique (learning from
                   the parental generation) and vertical (learning from
                   the parent). We suggest that the tendency to assort
                   may be advantageous in the context of social
                   learning, and that ASL might be an important concept
                   for the evolutionary theory of social learning.
                   {\textcopyright} 2014 The Society for the Study of
                   Evolution.},
  doi =           {10.1111/evo.12403},
  issn =          {15585646},
}

@article{Sandholm1996,
  author =        {Sandholm, Tuomas W. and Crites, Robert H.},
  journal =       {BioSystems},
  number =        {1-2},
  pages =         {147--166},
  title =         {{Multiagent reinforcement learning in the Iterated
                   Prisoner's Dilemma}},
  volume =        {37},
  year =          {1996},
  abstract =      {Reinforcement learning (RL) is based on the idea that
                   the tendency to produce an action should be
                   strengthened (reinforced) if it produces favourable
                   results, and weakened if it produces unfavourable
                   results. Q-learning is a recent RL algorithm that
                   does not need a model of its environment and can be
                   used on-line. Therefore, it is well suited for use in
                   repeated games against an unknown opponent. Most RL
                   research has been confined to single-agent settings
                   or to multiagent settings where the agents have
                   totally positively correlated payoffs (team problems)
                   or totally negatively correlated payoffs (zero-sum
                   games). This paper is an empirical study of
                   reinforcement learning in the Iterated Prisoner's
                   Dilemma (IPD), where the agents' payoffs are neither
                   totally positively nor totally negatively correlated.
                   RL is considerably more difficult in such a domain.
                   This paper investigates the ability of a variety of
                   Q-learning agents to play the IPD game against an
                   unknown opponent. In some experiments, the opponent
                   is the fixed strategy Tit-For-Tat, while in others it
                   is another Q-learner. All the Q-learners learned to
                   play optimally against Tit-For-Tat. Playing against
                   another learner was more difficult because the
                   adaptation of the other learner created a
                   non-stationary environment, and because the other
                   learner was not endowed with any a priori knowledge
                   about the IPD game such as a policy designed to
                   encourage cooperation. The learners that were studied
                   varied along three dimensions: the length of history
                   they received as context, the type of memory they
                   employed (look up tables based on restricted history
                   windows or recurrent neural networks that can
                   theoretically store features from arbitrarily deep in
                   the past), and the exploration schedule they
                   followed. Although all the learners faced
                   difficulties when playing against other learners,
                   agents with longer history windows, lookup table
                   memories, and longer exploration schedules fared best
                   in the IPD games.},
  doi =           {10.1016/0303-2647(95)01551-5},
  issn =          {03032647},
}

@inproceedings{Ndousse2021,
  author =        {Ndousse, Kamal and Eck, Douglas and Levine, Sergey and
                   Jaques, Natasha},
  booktitle =     {Proceedings of the 38th International Conference on
                   Machine Learning},
  title =         {{Emergent Social Learning via Multi-agent
                   Reinforcement Learning}},
  year =          {2021},
  abstract =      {Social learning is a key component of human and
                   animal intelligence. By taking cues from the behavior
                   of experts in their environment, social learners can
                   acquire sophisticated behavior and rapidly adapt to
                   new circumstances. This paper investigates whether
                   independent reinforcement learning (RL) agents in a
                   multi-agent environment can learn to use social
                   learning to improve their performance. We find that
                   in most circumstances, vanilla model-free RL agents
                   do not use social learning. We analyze the reasons
                   for this deficiency, and show that by imposing
                   constraints on the training environment and
                   introducing a model-based auxiliary loss we are able
                   to obtain generalized social learning policies which
                   enable agents to: i) discover complex skills that are
                   not learned from single-agent training, and ii) adapt
                   online to novel environments by taking cues from
                   experts present in the new environment. In contrast,
                   agents trained with model-free RL or imitation
                   learning generalize poorly and do not succeed in the
                   transfer tasks. By mixing multi-agent and solo
                   training, we can obtain agents that use social
                   learning to gain skills that they can deploy when
                   alone, even out-performing agents trained alone from
                   the start.},
  url =           {http://arxiv.org/abs/2010.00581},
}

@article{Gronauer2022,
  author =        {Gronauer, Sven and Diepold, Klaus},
  journal =       {Artificial Intelligence Review},
  number =        {2},
  pages =         {895--943},
  publisher =     {Springer Netherlands},
  title =         {{Multi-agent deep reinforcement learning: a survey}},
  volume =        {55},
  year =          {2022},
  abstract =      {The advances in reinforcement learning have recorded
                   sublime success in various domains. Although the
                   multi-agent domain has been overshadowed by its
                   single-agent counterpart during this progress,
                   multi-agent reinforcement learning gains rapid
                   traction, and the latest accomplishments address
                   problems with real-world complexity. This article
                   provides an overview of the current developments in
                   the field of multi-agent deep reinforcement learning.
                   We focus primarily on literature from recent years
                   that combines deep reinforcement learning methods
                   with a multi-agent scenario. To survey the works that
                   constitute the contemporary landscape, the main
                   contents are divided into three parts. First, we
                   analyze the structure of training schemes that are
                   applied to train multiple agents. Second, we consider
                   the emergent patterns of agent behavior in
                   cooperative, competitive and mixed scenarios. Third,
                   we systematically enumerate challenges that
                   exclusively arise in the multi-agent domain and
                   review methods that are leveraged to cope with these
                   challenges. To conclude this survey, we discuss
                   advances, identify trends, and outline possible
                   directions for future work in this research area.},
  doi =           {10.1007/s10462-021-09996-w},
  isbn =          {0123456789},
  issn =          {15737462},
  url =           {https://doi.org/10.1007/s10462-021-09996-w},
}

@inproceedings{Jaques2019,
  author =        {Jaques, Natasha and Lazaridou, Angeliki and
                   Hughes, Edward and Gulcehre, Caglar and
                   Ortega, Pedro A and Strouse, DJ and Leibo, Joel Z and
                   de Freitas, Nando},
  booktitle =     {Proceedings of the 36th International Conference on
                   Machine Learning},
  pages =         {10},
  title =         {{Social Influence as Intrinsic Motivation for
                   Multi-Agent Deep Reinforcement Learning}},
  year =          {2019},
  abstract =      {We propose a unified mechanism for achieving
                   coordination and communication in Multi-Agent
                   Reinforcement Learning (MARL), through rewarding
                   agents for having causal influence over other agents'
                   actions. Causal influence is assessed using
                   counterfactual reasoning. At each timestep, an agent
                   simulates alternate actions that it could have taken,
                   and computes their effect on the behavior of other
                   agents. Actions that lead to bigger changes in other
                   agents' behavior are considered influential and are
                   rewarded. We show that this is equivalent to
                   rewarding agents for having high mutual information
                   between their actions. Empirical results demonstrate
                   that influence leads to enhanced coordination and
                   communication in challenging social dilemma
                   environments, dramatically increasing the learning
                   curves of the deep RL agents, and leading to more
                   meaningful learned communication protocols. The
                   influence rewards for all agents can be computed in a
                   decentralized way by enabling agents to learn a model
                   of other agents using deep neural networks. In
                   contrast, key previous works on emergent
                   communication in the MARL setting were unable to
                   learn diverse policies in a decentralized manner and
                   had to resort to centralized training. Consequently,
                   the influence reward opens up a window of new
                   opportunities for research in this area.},
}

