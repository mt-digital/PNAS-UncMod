\documentclass[letterpaper,11.5pt]{scrartcl}
\usepackage{totcount}
\usepackage[chatter]{rotating}
% \documentclass[11pt]{report}
% \documentclass{report}
% \documentclass{book}
\usepackage[bookmarks, hidelinks]{hyperref}
\usepackage{amssymb,amsmath}
\usepackage[title]{appendix}
% \usepackage{fullpage}
\usepackage{tabulary}
\usepackage{tabularx}
\usepackage{float}
% \usepackage[margin=0.50in]{geometry}
\usepackage[margin=1.00in]{geometry}
% \usepackage[modulo]{lineno}
\usepackage{lineno}
\linenumbers

\usepackage{booktabs}
\usepackage{pslatex}
\usepackage{caption}
\usepackage{natbib}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{setspace}
\doublespace
% \usepackage{url}
\usepackage{bigfoot}
\usepackage[export]{adjustbox}
\setlength\intextsep{0pt}

\usepackage{xcolor}

% Colored comments 
\usepackage{color}
\definecolor{myorange}{RGB}{240, 96, 0}
\newcommand{\mt}[1]{{\textcolor{myorange} {({\tiny MT:} #1)}}}

\definecolor{myblue}{RGB}{30,144,255}
\newcommand{\jhj}[1]{{\textcolor{myblue} {({\tiny JHJ:} #1)}}}

\definecolor{mypurple}{RGB}{148,0,211}
\newcommand{\cm}[1]{{\textcolor{mypurple} {({\tiny CM:} #1)}}}

\definecolor{mygreen}{RGB}{26, 153, 51}
\newcommand{\ps}[1]{{\textcolor{mygreen} {({\tiny PS:} #1)}}}

\definecolor{editblue}{HTML}{1055CB}

% \newcommand{\edit}[1]{{\bfseries \textcolor{editblue} {#1}}}
\newcommand{\edit}[1]{{\bfseries \textcolor{blue} {#1}}}

\newtotcounter{citnum} %From the package documentation
\def\oldbibitem{} \let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citnum}\oldbibitem}

\usepackage{graphicx}
\usepackage{comment}

\usepackage{authblk}
\renewcommand\Affilfont{\small}

\author[1,2,*]{Matthew A. Turner}
\author[3]{Cristina Moya}
\author[4,5,6]{Paul E. Smaldino}
\author[1,2,6]{James~Holland~Jones}

\affil[1]{Department of Earth System Science, Stanford University, Stanford, CA 94305 USA}
\affil[2]{Division of Social Sciences, Stanford Doerr School of Sustainability, Stanford University, Stanford, CA 94305 USA}
\affil[3]{Department of Anthropology, University of California at Davis, Davis, CA 95616 USA}
\affil[4]{Cognitive and Information Sciences, University of California at Merced, Merced, CA 95340 USA}
\affil[5]{Santa Fe Institute, Santa Fe, NM 87501 USA}
\affil[6]{Center for Advanced Study in the Behavioral Sciences, Stanford University, Stanford, CA 94305 USA}
\affil[*]{Corresponding author; email: \href{mailto:maturner@stanford.edu}{maturner@stanford.edu}}

\title{The Form of Uncertainty Affects Selection for Social Learning}
%\title{Different forms of uncertainty differently affect the evolution of social learning}
%\title{The Many Faces of Uncertainty: ... }

\begin{document}
\maketitle
\clearpage


\newcommand{\pisub}[1]{\pi_{\mathrm{#1}}}
\newcommand{\pilow}{\pisub{low}}
\newcommand{\pihigh}{\pisub{high}}
\newcommand{\piI}{\langle \pisub{I} \rangle}
\newcommand{\piS}{\langle \pisub{S} \rangle}
\newcommand{\ledger}{\bar\pi_{ib}}

\newcommand{\meanvar}[1]{\langle #1 \rangle}
\newcommand{\meansl}{\meanvar{s}}
\newcommand{\meanpi}{\meanvar{\pi}}
\newcommand{\meansoc}{\meanvar{\pi_\mathrm{S}}}
\newcommand{\meanasoc}{\meanvar{\pi_\mathrm{A}}}
\newcommand{\meanT}{\meanvar{T}}
\newcommand{\meanG}{\meanvar{G}}

\newcommand{\bandit}{\text{Bandit}_b(0, 1)}

\begin{abstract} 
Social learning is a critical adaptation for dealing with different forms of variability. 
Uncertainty is a severe form of variability where the space of possible
decisions or probabilities of associated outcomes are unknown.
We identified four theoretically-important sources of uncertainty: temporal
environmental variability, payoff ambiguity, selection-set size, and effective lifespan. When these combine,
it is nearly impossible to fully learn about the environment. We develop an
evolutionary agent-based model to test how each form of uncertainty affects the evolution of social
learning. Agents perform one of several behaviors, modeled as a multi-armed bandit, to acquire
payoffs. \edit{All agents learn about behavioral payoffs individually through an adaptive
behavior-choice model that uses a softmax decision rule.} Use of vertical and oblique \edit{payoff-biased} social learning \edit{evolved} to serve as a scaffold \edit{for adaptive individual learning---they are not opposite strategies}. Different types of uncertainty had varying effects.
Temporal environmental variability suppressed social learning, whereas larger selection-set size
promoted social learning, even when the environment changed frequently. Payoff ambiguity and lifespan
interacted with other uncertainty parameters. \edit{This study begins to explain how social learning can predominate despite highly variable real-world environments when effective individual learning helps individuals recover from learning outdated social information.}
%, meaning social and individual learning complement one another
  % the importance of clearly operationalizing uncertainty for understanding its role in cultural evolution.
% Social learning is essential to human survival. It is likely to evolve when it is more
% efficient than asocial, trial-and-error learning. Theoretically, social learning
% is adaptive for some uncertainty, but too much uncertainty makes
% social information unreliable. This fact is empirically
% supported across biology and human sciences. However, it is unclear how
% specific classes and types of uncertainty affect social
% learning evolution. Furthermore, existing models and experimental operationalizations of
% uncertainty are ambiguously related, and 
% tend to only consider a small number of behavioral
% choices.  Here we use evolutionary agent-based modeling to consolidate
% models of uncertainty in social learning evolution to address these issues.
% We model societies of agents who perform one of a number
% of possible behaviors to acquire payoffs in a time-varying environment.
% We identified complex patterns in social learning evolution depending on contextual
% uncertainty variables: environmental variability, ambiguous payoffs, 
% decision sets size, and effective lifespans. 
% Our work advances social learning evolution theory in a way that could help 
% guide human, non-human, and artificial intelligence towards optimal responses 
% to existential threats and new opportunities.
% \footnote{This document contains
% \total{citnum} references.}  
\end{abstract}


\section{Introduction}

Social learning enhances problem solving when acquiring information from others is more efficient than learning on one's own~\citep{Laland2004}. However, social learning can also lead individuals astray if they are copying irrelevant, misleading, or outdated information. Theoretical models have helped clarify the circumstances under which social learning should be evolutionarily favored~\citep{BoydRicherson1985, aoki2014evolution,Kendal2018}, and these models have motivated empirical work that has both validated and refined theoretical predictions concerning the use of social learning in humans and other species~\citep{galef2005social,McElreath2005,Kendal2018,Allen2019}. This literature
indicates that social learning is a critical adaptation found across taxa for dealing
with variable environments. %When in doubt, copy others. 

Uncertainty weighs particularly heavily on human adaptation because of
our long lifespans, cosmopolitan distribution, and dispersal across highly variable environments, requiring coarse-grained and plastic behavioral adaptations \citep{levins1962}. However, the term ``uncertainty'' is often used loosely in a way that fails to distinguish it from risk. \emph{Risk} represents a decision with a variable payoff where the state space and probabilities associated with the different outcomes are both known. In contrast, \emph{uncertainty} implies that the outcome probabilities, and possibly the state space, are not known \citep{knight1921, keynes1921}. Furthermore, usage of the term uncertainty often conflates several different interpretations of that word. For example, different models define uncertainty in terms of the rate of environmental change, spatial environmental variation, or the reliability of information acquired from the environment. %Furthermore, in translating mathematical models to verbal predictions, the formal meaning of terms like uncertainty is often lost \citep{knight1921, lawson1988probability, volz2012}, facilitating such conflation. %Furthermore, it can be important to distinguish a narrower definition of uncertainty wherein the probabilities of outcomes remain unknown~\citep{knight1921,volz2012}. 
As the number of formal models of social learning has expanded, an increasing number of modeling choices~\citep{Kendal2018} and formalizations of
uncertainty have made it difficult to compare across models or to consolidate our
understanding of the contexts in which social learning under uncertainty is adaptive. 
% Finally, while risk and uncertainty are often used interchangeably to refer to
% non-deterministic outcomes, 

%Other (asocial) forms of learning are also likely adaptations to uncertainty that should be accounted for, but are typically glossed over in models.  
Learning, social or otherwise, is an iterative process during which an individual acquires information, forms representations and predictions, and then tests and refines those representations and predictions to manage uncertainty~\citep{jacobs2011bayesian,clark2013whatever}. Because cultural evolutionary models are frequently designed to explain \emph{social} learning mechanisms, they often contrast social learning with a simplistic mechanism for individual learning. In particular, a common assumption is that individual learners can pay a cost to definitively learn the optimal behavior for a particular environment with certainty. This assumption implies that social learning, by observing an individual learner, is a good bet if the environment has not changed. Such modeling choices may lead us to overestimate both the extent to which individual learning provides quality information and the value of social learning in a population of individual learners. % , both for asocially adapting to uncertainty and for social learners to take advantage of.
%and for the individual to adapt to the challenges assumed to be solved by social learning. 
% underestimate the quality of information
% available for social learning. 

To address these concerns we developed an evolutionary agent-based model that
simultaneously operationalizes several forms of uncertainty and endows agents
with a relatively powerful mechanism for individual learning. We model four kinds of
uncertainty that are common in cultural evolution models and the related empirical
literature:  (1) temporal environmental variability; (2) selection-set size (the number of possible behaviors); (3) payoff ambiguity
(the difference in the expected rewards for different behaviors); and (4) the effective lifespan of agents (the number of
opportunities for individual learning), see next section for more details. In our model, social learners learn from the previous
generation and asocial learners do not. All agents engage in individual learning
within their lifespans. The model also assumes \edit{an adaptive},
empirically-motivated learning mechanism, the softmax \edit{decision rule}, which allows learners to make full use of the available data acquired by both individual and social learning \citep{SuttonBartoBook}. Our model design thereby affords us a richer and possibly more accurate assessment of trade-offs between social and asocial learning. We use this integrated model to ask which kinds of uncertainty are likely to favor social learning and to clarify the logic underlying the results.
In the remainder of this introduction we briefly review previous research on both the forms of uncertainty and the learning mechanism used in our model. 


\subsection{Varieties of Uncertainty}

Uncertainty involves a reduced ability to predict what will happen in the future or to assess which actions are likely to yield particular outcomes. Uncertainty can manifest in many ways. We focus on the following four sources of uncertainty for the evolution of social learning: (1) temporal environmental variability, (2) selection-set size, (3) payoff ambiguity, and (4) effective lifespan.

\paragraph{Temporal environmental variability.} When environmental variability is nonstationary (for example, because of climatic events %, migration,
or technological paradigm shifts), strategies that were previously adaptive may no longer be optimal. The difficulty in predicting either when such shocks will occur or which behaviors will be adaptive in the resulting environments leads to uncertainty. 

Temporal environmental variability is fundamental to most evolutionary models of
social learning. Such fluctuations have been proposed as an important selective
pressure for learned as opposed to genetically fixed behaviors when genetic adaptation cannot keep pace with environmental change~\citep{Richerson2000}. On the other hand, environments that change \emph{too} quickly will select against social learning so that individuals avoid learning outdated---and therefore maladaptive---information~\citep{Feldman1996,
BoydRicherson1985}. This suggests that intermediate levels of temporal variation
are important for the evolution of social learning mechanisms~\citep{aoki2005}.

%Despite the theoretical centrality of t
Temporal environmental variability tends to be modeled in one of 
several ways~\citep{aoki2014evolution}. Most commonly, it is modeled
as an independent probability that the environment changes its state (and its corresponding optimal behavior) before each new generation~\citep{BoydRicherson1985,Rogers1988,Feldman1996,McElreath2005,Enquist2007,perreault2012bayesian,aoki2014evolution}, but
% The probabilities of environmental change are usually fixed per generation
%~\citep{BoydRicherson1985,Rogers1988,kendal2009evolution}, 
it has also been modeled using deterministic cycles, so that environments repeat at regular intervals~\citep{Feldman1996, aoki2014evolution}.
%Furthermore, t
The consequences of environmental change can range from mild to catastrophic. In the latter case, a change of environment results in the total elimination of any adaptive behavior, which must be learned \emph{de novo} for the new environment~\citep{Rogers1988}. Such catastrophic environmental changes present
a large adaptive challenge as individuals cannot rely on accumulated information
from previous generations. Other models of environmental change introduce less
uncertainty as they fluctuate between two or more environmental states with corresponding adaptive behaviors. This means that previously maladaptive
behaviors become adaptive when the environment changes~\citep{perreault2012bayesian}. The chosen mechanism for modeling temporal change has important theoretical consequences, reviewed in Aoki \& Feldman (2014).~\nocite{aoki2014evolution} Our study design ignores cases where temporal variation is low enough that genetic selection can canalize a behavior, and instead considers only behaviors that can be learned.


\paragraph{Selection-set size.}
When one does not know which option to take, uncertainty increases with the number of options, which we call the selection-set size.
% This is a mathematical fact at the
% core of information theory: the number of bits required to reliably encode the optimal solution increases by one every time the
% selection-set doubles in size~\citep{mackay2003information}. 
% This is intuitive; the more options to consider, the greater one's uncertainty about which option is the best choice. 
In many studies of social learning, the selection set is often limited to just two options.  For example, in empirical studies of bumble bees (\emph{Bombus
terresteris}) \citep{Baracchi2018} and great tits (\emph{Parus major}) \citep{Aplin2017}, experimenters provided two behaviors from which the bees or birds
could choose, with one yielding a higher payoff than the other. %respectively,
%each yielding greater or smaller payoffs depending on experimental treatment.
Similarly, many human studies have used just two or three possible
behaviors~\citep{McElreath2005,Morgan2012, Toyokawa2019}. The designs of behavioral experiments are 
often motivated by modeling studies with similar formulations~\citep{Rogers1988,boyd1995does,Feldman1996,
perreault2012bayesian}.
Larger, more open sets of behavioral choices are not uncommon in experiments trying to capture more complex or naturalistic tasks~\citep{derex2013, wasielewski2014}, but these map imperfectly onto the theoretical literature that tends to use a limited set of behavioral options.
Some models have studied systems with larger, but defined, selection sets~\citep{Rendell2010, lindstrom2016co}, while in others the number of options is subsumed under the probability that a learner gets the right  answer~\citep{Feldman1996,Enquist2007}.
%\mt{How does this work exactly in Enquist et al 2007?}. 
%Researchers have also compared models with a different number of environment states, corresponding to a different number of optimal behaviors through time~\citep{Feldman1996}. 
Rarely is the size of the selection set explored explicitly as a source of  uncertainty \citep[though see][]{Muthukrishna2016a}, even though the number of options one has is likely to increase the difficulty of the decision task~\citep{haynes2009testing,white2009testing}.  
%These examples share one common feature: the size of the selection set was held static \emph{within} model generations.
% as a measure of changing uncertainty in cultural evolutionary models.

\paragraph{Payoff ambiguity.} Most models of social learning necessarily differentiate between the payoffs for adopting optimal vs. non-optimal behaviors
\citep{BoydRicherson1985,Rogers1988,Enquist2007,Rendell2010,aoki2014evolution}. The size of the difference between these payoffs is usually taken to influence the strength of selection on learning strategies.
However, the ability to discern payoff differences between behaviors is also a source of uncertainty. In reality, payoffs for particular behaviors are not always consistent. A behavior may yield a large payoff sometimes and a small
payoff other times \citep{McElreath2005}. This means that signals about the
relationship between behavior and payoff are often noisy, and differentiating
between behavioral options is in part a problem of signal detection. When the
difference in expected payoffs between optimal and non-optimal behaviors is very
large, this noise matters little, as the signal is still very clear. However, when
the expected payoffs of different behaviors are similar relative to the size of
their variances, ambiguity arises about which behaviors really are superior.
Smaller differences between payoffs corresponds to larger ambiguity. Payoff
ambiguity has been manipulated in both theoretical~\citep{perreault2012bayesian}
and empirical~\citep{McElreath2005,Toyokawa2019} studies, both of which support the
claim that payoff ambiguity increases the reliance on social information.
Importantly, payoff ambiguity %differs from selection-set size in that it not only 
affects both uncertainty \emph{and} the strength of selection, with smaller payoff differences leading to greater uncertainty for a learner and weaker evolutionary selection favoring optimal strategies. 
\edit{It is an outstanding problem to understand how payoff variance and payoff
distributions generally affect evolved behavioral strategies~\citep{Haaland2019}.
For the sake of theoretical clarity for our goal of understanding the
\emph{interaction} of various sources of uncertainty, we only operationalize payoff
ambiguity as the difference between expected payoffs, even though empirical studies
have sometimes included both forms of payoff uncertainty~\citep{McElreath2005,Toyokawa2019}, and a more complete model would include differences in mean and variance of payoffs.}

%This parameter sometimes takes the form of differences in
%expected payoffs arising from different behaviors or strategies~\citep{Enquist2007,Rendell2010} or by varying the standard deviation of payoffs~\citep{McElreath2005}. 

\paragraph{Effective lifespan.} The more opportunities an agent has to learn during its lifespan, the more uncertainty can be reduced, assuming a stationary environment. Correspondingly, a reduction in the number of opportunities to learn will increase the uncertainty about which behavioral options are available and what their associated
payoffs are. %Such uncertainty can be passed on to future generations.
% Learning is an iterative process by which one repeatedly acquires information, forms
% representations and predictions, and tests and refines those representations and
% predictions to manage uncertainty \citep{jacobs2011bayesian,clark2013whatever}. 
We refer to the number of individual learning opportunities within a generation as an individual's \emph{effective} lifespan to highlight that it is the number of opportunities to learn about the payoffs associated with a behavior, rather than the number of sunrises one experiences, that determines one's uncertainty about the behavioral options.  
%throughout the individual's lifespan that matters here, not necessarily how long they live in the absence of relevant learning opportunities.  

Empirically, the number of learning opportunities can be manipulated in the lab and in the real world will tend to correlate with an individual's relative age. In multi-round studies of information use in novel tasks, US participants' use of social
information declined precipitously across rounds~\citep{McElreath2005}, suggesting
they were more likely to use social information when they were most uncertain about the task early on. In a more naturalistic context, \citet{Aplin2017} found that younger great tits more readily used social information compared to older individuals, possibly because they had accrued less information via individual learning, and possibly because younger individuals have the most to gain (because of higher reproductive value) by switching to superior behavioral options. Cross-cultural studies have highlighted the importance of childhood as a phase of heavy social learning in humans \citep{Reyes2016}. Young children are more likely to
acquire their beliefs and simple skills from their parents than are older children
or adults, which is at least partly due to the differential knowledge accrual
between young children and the older adults to whom they direct the most trust and
attention \citep{kline2013teaching}. While these phenomena map imperfectly onto effective lifespan in our model, given social learning is only allowed intergenerationally, \edit{the relative number of individual to social learning opportunities, i.e., this model's version of }effective lifespan, do vary across tasks, individuals, and species, yet most models assume only one learning opportunity per generation \citep{BoydRicherson1985, Feldman1996,Henrich1998, perreault2012bayesian}. Some models do allow several cultural generations within one genetic generation \citep{Enquist2007,Rendell2010,lindstrom2016co}, but little formal theory explicitly examines the role of learning opportunities in the evolution of social learning. 

%To answer our research questions about the combined effect of various forms of uncertainty on social learning evolution, we developed an agent-based model that incorporates all four of these uncertainty variables. We systematically vary these parameters to understand and predict their effects on social learning evolution.


\subsection{Individual-level adaptations to uncertainty} 

While the cultural-evolution literature suggests that several forms of uncertainty have played a role in the evolution of social learning, other cognitive mechanisms have likely also evolved in response to uncertainty \citep{volz2012,johnson2013evolution,van2018uncertainty}. Many of these are flexible learning mechanisms that do not require imitating the behaviors of others. For example, when faced with greater uncertainty, individuals may adopt more exploratory learning strategies and may even preferentially test behaviors with greater observed payoff variance \citep{Wilson2014,Gershman2019}.

Many models of social learning simplify by using minimally-cognitive agents. For example, a common modeling strategy compares the payoffs of agents with different pure learning strategies (e.g., those who only engage in social learning versus those who only engage in individual learning) while revealing nothing about the cognition underlying individuals' decisions~\citep{BoydRicherson1985, Rogers1988, 
aoki2005}. This sort of behavioral gambit is common in evolutionary modeling, but has also been criticized as `blackboxing' key cognitive processes that are important to cultural evolution \citep{Heyes2016,Kendal2018}.  
Some more complicated learning strategies that make use of both socially and
individually learned information have been studied ~\citep{Enquist2007,
perreault2012bayesian}, including those that integrate cognitively plausible
mechanisms such as reinforcement learning \citep{lindstrom2016co}, though the latter
approach remains the exception rather than the norm. In order to understand how
social learning evolves as an adaptation to uncertainty, we endowed agents with an
\edit{adaptive} cognition based on a softmax decision rule capable of integrating information from various sources to maximize payoffs~\citep{Gershman2019}, described in more detail below. 

\section{Model}

In our model we allow just one trait to evolve: social learning. All other parameters are exogenous. Our primary outcome measure is the observed frequency at which the social-learning trait fixates in simulated populations. We study how the social learning fixation frequency responds to each of the four varieties of uncertainty considered in this paper. 

A population consists of $N$ individuals, each of whom must decide which of $B$ behaviors to perform at
each time step within a generation consisting of $L$ time steps. The behavioral selection set is a multi-armed bandit with $B$ arms. That is, agents can pick one of $B$ behaviors with random-valued payoffs~\citep{SuttonBartoBook,McElreath2005,Steyvers2009,Rendell2010,Schulz2019}. In each generation, exactly one behavior is more likely to pay off than all the rest and is therefore optimal. Agents optimize their net payoffs over their lifespan by quickly learning which behavior is optimal and performing it as often as possible within their lifespan. At the end of each generation, agents are selected with replacement to reproduce a new generation of $N$ agents, with the probability of reproduction biased by net payoffs. Agents who inherit the social-learning trait learn about payoffs from the previous generation, while asocial learners begin life only knowing the number of behaviors the environment affords, but have no knowledge of behavioral payoffs.


\subsection{Model environment and uncertainty}

The structure of the environment is specified by several parameters that remain fixed throughout the course of a given simulation (Table~\ref{tab:uncertaintyParameters}).  The environment affords $B$ behaviors, where $B$ is the \emph{selection-set size}. Uncertainty increases with $B$. Each behavior is indexed by $b$ and yields a payoff of 1 with probability $\pi_b$ and a payoff of 0 otherwise. As such, $\pi_b$ is equivalently the expected payoff of behavior $b$. At the beginning of each generation, one behavior is optimal and yields expected payoff $\pihigh$; the other $B-1$ behaviors yield a lower payoff, $\pilow$. The \emph{payoff ambiguity} is defined by $\pihigh - \pilow$. We fix $\pihigh = 0.9$ to be constant across all simulations, so payoff ambiguity is varied by changing the value of $\pilow$. In other words, payoff ambiguity, and therefore uncertainty, increases with $\pilow$.  Agents have $L$ time steps to \edit{act and learn asocially} per generation (i.e., the \emph{effective lifespan}). Uncertainty decreases with $L$. At the start of each generation a new optimal behavior is selected at random from the set of all possible behaviors with probability $u$ (the \emph{environmental variability}), otherwise the optimal behavior remains unchanged from the previous generation. Uncertainty increases with $u$.

\vspace{2em}
\begin{table}[h]
\caption{Environmental parameters. These include our four main uncertainty parameters under investigation; 
$\pilow$, $B$, $L$, and $u$. Bold indicates default value tested.} %\emph{default value tested}.}
    \label{tab:uncertaintyParameters}
    \centering %\hspace{-3em}
    \begin{tabular}{cp{4.0in}p{1.25in}} \toprule

        Symbol & Description & Values tested \\ 

        \midrule  
        $N$    & Population size
                 & 50, 100, 200, \textbf{1000} \\
               

        $\pihigh$ & Probability that the unique optimal behavior pays off 1 
                & \textbf{0.9} \\

        $\pilow$ & Payoff ambiguity: probability one of $B - 1$ non-optimal behaviors pays off 1
                 & 0.1, 0.45, 0.8 \\ 

        $B$       & Selection-set size: number of behavior options
                  & 2, 4, 10 \\
                  
        $L$    & Effective lifespan: time steps per generation & 1, $B/2$, $B$, $2B$, $4B$ \\
        
        $u$    & Environmental variability: Probability optimal behavior changes between generations
               & 0.0, 0.1, \ldots, 1.0 \\
               
        \bottomrule
        \end{tabular} 
\end{table}



\subsection{Agents and learning}

%Agents are endowed with dynamic attributes to intelligently select behaviors and calculate average payoffs for each behavior. 
All agents learn individually over their lifespan, and those with
the heritable social learner trait additionally use social information to constrain their individual
learning. For simplicity, we refer to agents with the social learner trait 
as social learners. 
% Learning strategies are assumed to be heritable. Each agent $i$ has a learning trait $s_i$, which is 1 if $i$ is a social learner and zero otherwise. 
% Every agent engages in individual learning over its lifespan, regardless of learning strategy. 
Social learners begin life with behavioral preferences based on information learned from an agent chosen from the previous generation. Asocial learners begin life with no behavioral preferences. Agent-level parameters are described in Table~\ref{tab:modelParameters}. 


\subsubsection{Individual learning}

All agents perform individual, trial-and-error learning at each time step in
their lifespan.  Learning is guided by softmax search. Softmax search
guides agents to exploit more frequently the most profitable behaviors when the
agent is more certain it is the optimal one and to explore more frequently when the
agent is unsure. To do softmax searching, agents track average payoffs acquired
from each behavior they have performed, which requires knowing the number of times they have performed each behavior. The probability that the agent will perform a behavior is a function of the agent's beliefs about a behavior's average payoff in that time step and a fixed parameter that influences the amount of exploratory behavior (more details below). The softmax function used here is a biologically plausible generalization of behavior selection under uncertainty that enables agents to often greedily exploit the most lucrative behavior they have observed, but also to sometimes explore alternatives~\citep{Schulz2019,Collins2013,Daw2006,Yechiam2005}.


\subsubsection{Social learning}

At the beginning of each generation other than the first, each social learner selects
one member of the previous generation to learn from in a payoff-biased way. 
%, if the child inherited $s_i = 1$. A child agent $c$ is a social learner if its parent $p$ was a social learner, i.e.\ $s_c \leftarrow s_p$, without mutation.
A social learner selects this ``teacher" from the previous generation by first
choosing the payoff maximizer among these (more details below).  The social learner then inherits information about the likely payoffs of each behavior from that one teacher, whereas asocial learners do not acquire this information. In this way, the social learner can potentially reduce the amount of exploration needed to both execute and learn about the optimal behavior.  


% \subsubsection{Social learning as a scaffold for individual learning}

% In this model, being a social learner is beneficial when it is more likely on
% average to provide greater net payoffs than being an individual learner.  It is not
% catastrophic for an individual to receive outdated information, as is sometimes
% assumed~\cite[e.g.]{Rogers1988}. Instead, agents explore alternatives and
% greedily perform different behaviors that pay off better. 
% This mechanism is critical for explaining the patterns we observe in the 
% Analysis, where social learning evolves when $u > 0.5$.
% In this case, the optimal behavior will switch between generations more often than
% not. Without individual learning, social learning would not evolve when $u > 0.5$.

\begin{table}[h]
  \vspace{2em}
  \caption{Agent-level variables. The first four ($\protect s_i$, $\protect
    \bar\pi_{ib}$, $\protect c_{ib}$,
  and $\protect \pi_i$) are dynamic with an implicit time dependence. The softmax
greediness $\protect \beta$ and number of prospective teachers for social learners,
$\protect N_T$, are constant throughout each simulation.}
    \label{tab:modelParameters}
    \centering \hspace{-1em}
    \begin{tabular}{cp{4.5in}p{1.25in}} \toprule

        Attribute & Description & Initial value \\ 

        \midrule  

        $s_i$  & Social-learner trait: 1 if agent $i$ is social learner; 0 otherwise & 0
        or 1 equally likely \\

        $\bar\pi_{ib}$ & Mean payoffs acquired by agent $i$ from behavior $b$
                       & $B$-vector of zeros \\

        $c_{ib}$ & Count of how many times agent $i$ performed behavior $b$ 
              & $B$-vector of zeros \\

        $\pi_i$ & Net payoffs accumulated by $i$ within generation & 0.0 \\

        $\beta$ & Softmax greediness: $\uparrow=$more exploitation, $\downarrow=$more
                    exploration 
               & 1, \textbf{10}, 100 \\
        
        $N_T$    & Number of teachers to pool, from which best selected 
                 & 2, \textbf{5}, 10, 20  \\

        \bottomrule
    \end{tabular}
\end{table}



\subsection{Dynamics}

Model dynamics proceed by first initializing the environment and agents according
to the chosen parameter settings. % for the simulation.
Then, within each generation, agents select and perform behaviors, updating their estimated payoffs, and thus their probabilities of choosing each behavior, along the way.
Between generations, agents reproduce, teach social learners of the next generation, and die off. 
%Child agents then begin a new round of generational dynamics, followed by reproduction. 
This process continues until the population has evolved to fixation as either all social learners or
all asocial learners. %This process is represented in Figure~\ref{fig:schematic}.


\paragraph{Initialization.}

The model is initialized with $N$ agents. Each agent $i$ tracks 
observed mean payoffs for each behavior, $b$, which is denoted $\ledger$. Each
agent $i$ also counts how many times they have tried each behavior $b$, 
denoted $c_{ib}$. At model initialization, $\ledger = 0.0$ and $c_{ib} = 0$ for
all $i$ and $b$.% (Figure~\ref{fig:schematic}A).
One of the behaviors is chosen at random to yield expected payoff $\pihigh$, with the other $B-1$ behaviors yielding
expected payoffs $\pilow$. Agents are independently randomly initialized with $s_i
\in 0,1$, so that $\sim$50\% of the initial population learn socially.


\paragraph{Within-generation dynamics.}
% To guide behavior selection, agent $i$ counts how many times it
% performed each behavior $b$, denoted $c_{ib}$. Agents use this count to 
% update the mean payoff they have obtained from behavior $b$, denoted $\ledger$.
% $\ledger$ is initialized to 0 for all $b$ at model start for
% all agents (Figure~\ref{fig:schematic}A), and at 
% generation start for asocial learners. Social
% learning agents' $\ledger$ is initialized as that of its teacher, who is selected
% through performance-biased oblique learning; $c_ib$ is set to 1 for all social
% learners $i$ and behaviors $b$ (Figure~\ref{fig:schematic}C). Agent $i$'s
% accumulated payoffs from performing several behaviors over their lifetime of $L$
% time steps is denoted $\pi_{i}$. If an agent $i$ is a social learner, then we write
% $s_i = 1$, otherwise the agent is an asocial learner and $s_i = 0$.

Within each generation, all $N$ agents perform $L$ behaviors sequentially and
independently (Figure~\ref{fig:softmaxSensitivity}b).
% Each agent $i$ selects one behavior on each step of its lifespan using softmax applied
% to the vector of mean payoffs the agent has observed for each behavior
% ($\ledger$), integrating previous knowledge. 
% We denote the average payoffs obtained by agent $i$
% for behavior $b$ as $\ledger$. We denote the number of times $i$ performed $b$
% as $c_{ib}$ (``$c$'' stands for count). 
At each time step, agent $i$ performs behavior $b$ with softmax-weighted probability
\begin{equation}
  \Pr(\text{Agent $i$ performs behavior $b$}) = 
    \frac{e^{\beta \ledger}}{\sum_{b=1}^B e^{\beta \ledger}}.
\end{equation}
\noindent
$\beta$ adjusts how frequently agents perform 
behaviors with high expected payoffs (larger $\beta$) versus how frequently
agents explore alternative behaviors (smaller $\beta$). %~\citep{McElreath2005}. 
We used a default value of $\beta = 10$, but also varied this value in our
sensitivity analyses~(Figure~\ref{fig:softmaxSensitivity}). 

Agent $i$ using behavior $b$ receives a payoff of 1 with probability $\pihigh$
if $b$ is the optimal behavior, or with probability $\pilow$ otherwise. 
%Agents probabilistically recieve a payoff of 0 or 1 depending on whether the bandit paid off. Behavior payoffs are drawn from a Bernoulli distribution with mean $\pi_b$, so $\pi_b$ is also the mean payoff from behavior $b$.  For concreteness we denote this probabilistic payoff $\bandit$. 
After performing behavior $b$, agent $i$ updates its
corresponding \emph{behavior count} for $b$ by 1, $c_{ib}' \leftarrow c_{ib} + 1$.
Then the observed average payoffs known by agent $i$ for behavior $b$ are updated
via \edit{moving arithmetic averaging},
\begin{equation}
  \ledger' \leftarrow \ledger + \frac{\bandit - \ledger}{c_{ib}'},
\end{equation}
\noindent
where $\bandit$ is the actual payoff received by agent $i$ for behavior $b$ on a
given %(implicit) 
time step. \edit{This form allows the running mean payoffs to be calculated for each
behavior, weighting each observation equally, without knowing in advance how many
times a behavior will be performed. While more or less sophisticated averaging may
better represent specific species' abilities in different contexts, this form
provides a basic observational learning mechanism that may be further specified as
appropriate for different cases.}

\paragraph{Intergenerational dynamics.} Between generations, agents first reproduce
via asexual haploid reproduction, which determines the transmission of the social
learning trait. Social learners then learn from the previous generation, after which
all agents from the previous generation die off. % (Figure~\ref{fig:schematic}C). 
More
specifically, this all happens as follows.  $N$ reproducers are selected with
replacement over $N$ independent draws, biased by performance: 
\begin{equation}
  \Pr(\text{Agent $i$ is chosen to reproduce in one draw}) =
\frac{\pi_i}{\sum_{i=1}^N \pi_i}.  
\end{equation} 
\noindent 
A child inherits its parent's social-learning trait $s_i$ without mutation.  A social learner child with $s_i = 1$ learns from a teacher from its parent's generation, including possibly their parent (i.e., both vertical and oblique learning are possible).  A child chooses its teacher by first randomly selecting $N_T$ prospective teachers from the population, then selecting the one in this set with the greatest payoff net, with ties broken randomly. By first subsetting $N_T$ prospective teachers we represent the fact that access to the entire population is not generally guaranteed, though this type of algorithm yields qualitatively similar results to ones that do not first produce subsamples \citep{smaldino2019open} and we show in the supplement that our results are robust to different $N_T$
(Figure~\ref{fig:nteachersSensitivity}). Social learner $i$ adopts their chosen 
teacher $j$'s observed average payoffs for each behavior, $b$, i.e., 
$\ledger \leftarrow \bar\pi_{jb}$; 
and agent $i$'s count of behavioral observations, $c_{ib}$, is set to 1 if teacher $j$ had at least
one observation of behavior $b$, and $c_{ib}$ is set to 0 otherwise. This way, expected payoffs
remain within $[0, 1]$, but social learners are flexible to adjust to environmental change. Setting
$c_{ib}$ to 1 reflects the fact that the social learner treats the teacher's information as a single
observation with the associated uncertainty. \edit{If learners have more confidence
in the teacher's information, or there are biological or cultural factors that more
strongly weight teacher information, it may be more justifiable to set the learner's $c_{ib}$ to its teacher's $c_{jb}$}. Asocial learners ($s_i = 0$) are initialized with
$c_{ib} = 0$ and $\ledger = 0$ for each behavior, $b$. % (Figure~\ref{fig:schematic}C). 
The newly initialized population then repeats the within-generation dynamics. 

After reproduction and die-off, the optimal behavior changes with probability
$u$. The new behavior is chosen from all other behaviors, with the 
current optimal behavior excluded from selection.

\paragraph{Stopping condition.} The evolutionary process continues until the
population reaches evolutionary fixation with respect to social learning, that is, when
$\sum_i s_i = N$ or $\sum_i s_i = 0$. 

\clearpage

\begin{figure}
  \caption{\edit{Model summary}. Agents are randomly initialized as social learners or not, with their
  payoff observations all initialized to zero (A). Then agents begin selecting
and performing behaviors and accumulating payoffs, which goes on for $L$
timesteps (B). After $L$ time steps, agents are selected to reproduce,
social learner children learn from a member of their parent's generation, and
the previous generation dies off (C). The simulation stops if children are all
social or asocial learners (i.e.\ the system reaches fixation).
Otherwise it repeats another generation and evolution continues.} 
% \cm{What does (3) denote at end of Fig 1 caption? Does having only green agents in Fig1B give the impression that only social learners are learning within lifetime? Could the agent be half green/purple? Is it weird that in Fig1C a teacher with relatively low payoffs is being selected? Could be fixed by having the dotted line go from rich purple women's head to green baby's. }
  \label{fig:schematic}
  \centering
    \includegraphics[width=1.05\textwidth]{Figures/IntraInterGenerationalDynamics.pdf}
\end{figure}


\subsection{Computational analyses}
\label{ssec:computationalAnalyses}

% We developed a series of computational
% analyses of the effect of uncertainty on social learning evolution by 
% systematically varying uncertainty parameters and observing how
% frequently model populations evolve to be social learners.  

To analyze the effect of the four principal uncertainty factors, we systematically
varied uncertainty values %(Table~\ref{tab:modelParameters}) 
and observed how frequently social learning evolved across 1000 trial simulations for each combination of parameters tested. %We varied $u \in \{0.0, 0.1, \ldots, 1.0\}$; $\pilow \in \{0.1, 0.45, 0.8\}$; $B \in \{2, 4, 10\}$; and $L \in \{1,2,4,8\}$ for $B=2$ and $L \in \{1,B/2,B,2B\}$ for $B=4,10$.  
\edit{We observed three outcome measures: first, the social learning (SL) fixation frequency, denoted $\meansl$, is how frequently social learning evolved to fixation across all trials for a given parameter setting. To support our analysis about why we observed the patterns in social learning fixation frequency that we did, we also measured the mean number of generations to fixation, which measures the strength of selection.} Finally we measured the average net payoffs at the end of the simulation across agents and trials, normalized by lifespan. We analyze
outcomes by plotting $\meansl$ on the y-axis and environmental variability on
x-axis, since we theoretically expect that $\meansl$ will always decrease monotonically from 1 to 0 as $u$ increases. %Note that the hypothesis-testing concept of significance is meaningless here because we could make any small outcome difference ``significant'' by running more simulation trials.  We instead study the patterns of outcome variables over systematically varied uncertainty factor values. 

\begin{table}[h]
    \caption{Outcome variables. All averages are computed across trials at the end of the last generation.}
    \label{tab:outcomeVariables}
    \centering %\hspace{-3em}
    \begin{tabular}{clp{0.85in}} \toprule

        Symbol & Description & Values \\ 

        \midrule  

        $\meansl$ & Social learning fixation frequency (Figure~\ref{fig:mainResults})
                  &  $[0.0, 1.0]$ \\

        $\meanG$ & Mean time to fixation in units of generations (Figure~\ref{fig:steps}) & \{1,2,\ldots\} \\

        $\meanpi / L$ & Mean payoffs accumulated across agents, normalized by
        lifespan (Figure~\ref{fig:payoffs}) & $ [0.0, 1.0]$ \\

        \bottomrule
    \end{tabular}
\end{table}





\subsubsection{Implementation}

Our model was implemented in the Julia programming language~\citep{Bezanson2017} 
using the Agents.jl agent-based modeling library~\citep{Datseris2022} and run
on the Sherlock supercomputing cluster at Stanford University. All Analysis figures
except Figure~\ref{fig:slCeiling} were made using the Julia plotting
library Gadfly~\citep{Jones2021b}. Figure~\ref{fig:slCeiling} was made in R~\citep{R}
using the ggplot2 package~\citep{ggplot2}. 
Model and analysis code is publicly available on GitHub at \url{https://github.com/mt-digital/UncMod}.


\section{Analysis}

Our main results are illustrated by Figure~\ref{fig:mainResults}, which shows the
proportion of simulation runs that fixated at 100\% social learners as a function of
each of our four uncertainty measures. First, we found that reliance on social
learning monotonically decreases as temporal environmental variability, $u$,
increases \edit{(Figure~\ref{fig:mainResults})}. 
When the environment is more likely to change between generations,
information learned from the previous generation is less likely to be of value,
decreasing selection for social learning.  
However, the exact nature of the relationship between social
learning and temporal environmental variability was moderated by the other three uncertainty parameters. 

\edit{Across all parameter settings, we observed that there exists some threshold value of environmental
  variability beyond which the evolution of social learning is exceedingly rare.  We call this the
  \emph{social learning ceiling}, denoted $u_\text{c}$ (Figure~\ref{fig:slCeiling}), which is expressed formally as 
\begin{equation}
  u_\text{c} = \min~\{ u~|~\meansl < 0.01 \}.
  \label{eq:slCeiling}
\end{equation}
\noindent
In other words, $u_\text{c}$ is the smallest value of $u$ for which social learning fixated
less than one in one hundred times. We will use this auxiliary measure to analyze the effect of
the other uncertainty parameters and to highlight that social learning frequently 
evolves despite high levels of environmental variability.}

The number of behavioral options, i.e., larger $B$, favors the evolution of social learning. Increasing the selection-set size
expands the range of $u$ over which social learning is favored for two reasons. First, when the environment remains constant between
generations, the value of social learning increases with more behavioral options, because it effectively increases the number of
observations that one can learn from by comparing the payoffs of several models. In other words, relying \emph{only} on one's
individual trial-and-error learning is less likely to yield useful information when the search space is
large. Second, when the environment changes, bias against the new optimal is weaker with more behavioral
options. For example, with only two behavioral choices ($B = 2$), a common assumption in many models, social
learning is particularly detrimental when the environment changes, since more of the population will have
arrived at the optimal behavior in the previous generation and socially learning from them will be biased
against the correct choice. These two mechanisms make it particularly profitable to engage in social
learning when the selection-set size is larger---for large values of $B$ social learning can even be favored
when the environment is more likely to change than not (i.e.,
$u>0.5$\edit{---see Figure~\ref{fig:slCeiling}}). 

A shorter effective lifespan, $L$, also favors the evolution of social learning in
most cases. When effective lifespans are long and there are many opportunities to
gather information by individual learning, the value of social transmission is
diminished. Given enough opportunities, all agents will learn the optimal behavior
eventually. Thus, under most conditions, longer effective lifespans lead to a
narrower range of the parameters $u$ and $B$ under which social learning was
favored. It is noteworthy that in many cases, a large increase in the selection
regime for social learning is observed when $L=1$, and by definition no individual
learning can occur. The exceptions to this general pattern occur for high levels of
payoff ambiguity, $\pilow$ combined with low rates of environmental change, $u$
(left parts of plots on bottom row of Figure~\ref{fig:mainResults}). This reversal
is partially explained by \edit{weaker selection} when there is little difference in the payoffs between
behaviors, and by the fact that the quality of social information is poorer when payoffs are ambiguous and
lifespans are short (more on these effects of payoff ambiguity below).  
\edit{When $L$ becomes roughly equal to or greater than $B$ there is little marginal effect of increasing $L$, indicating that more individual learning experiences are unlikely to significantly affect an agent's ability to identify the optimal behavior in their lifetime.}
% \cm{is this right? I thought we should say something about the exceptions in this paragraph though we describe in more detail below, but not sure I have the right explanation}

Of the four types of uncertainty studied in this paper, payoff ambiguity had the most
complex effect on the evolution of social learning. Recall that we operationalized
payoff ambiguity with $\pilow$, the expected payoff for non-optimal behaviors
(equivalently the probability that those behaviors yielded a payoff of 1). This was
relative to $\pihigh = 0.9$, the expected payoff for the optimal behavior. When
payoff ambiguity was low, non-optimal behaviors rarely paid off, so that exploration
yielded reliable information and selection on learning strategies was strong. When
payoff ambiguity is very high ($\pilow = 0.8$), two things happen. First, agents are
more likely to err by ascribing high value to non-optimal behaviors, since it is
more difficult for them to discern the difference between optimal and sub optimal
behaviors. Second, and perhaps more importantly, natural selection on strategies
that \emph{do} reliably select the optimal behavior is relatively weak. This means
\edit{selection} is weaker \emph{in favor} of social learning under low values of $u$ and
\edit{weaker} \emph{against} social learning under high values of $u$ (Figure~\ref{fig:mainResults}, bottom row). 
This effect was especially \edit{pronounced} under other types of uncertainty, i.e., larger selection-set sizes and shorter effective lifespans---particularly when $L=1$ where no individual learning occurred. 

The effect of \edit{selection strength} when the benefit of social learning is ambiguous is powerful and complex. We explain how the frequency of social learning evolves in such circumstances in the following section.
%selection on social learning responds to these effects in more detail in the following section. 
%\cm{I rephrased as I didn't think selection was RESPONDING to drift. Original framing sounded weird since in essence we have weak selection which is why drift is relatively high. }



\begin{figure}
  \caption{\edit{Effect of four forms of uncertainty on evolution of social learning}. Social learning fixation frequency across trials (y-axes) monotonically decreases as 
  environmental variability, $u$, increases (x-axes) in most uncertainty contexts. 
  Other uncertainty values payoff ambiguity, $\pilow$, (rows), number of behavioral options, $B$, (columns), and effective lifespan, $L$, (keys) shift and flatten the slope from all-social-learner populations to all-asocial-learner
  populations.}
  \label{fig:mainResults}
  \centering
    \includegraphics[width=\textwidth]{Figures/mainResultsPlots.pdf}
\end{figure}


\begin{figure}
  \caption{\edit{Effect of uncertainty on social learning ceiling.} As the selection-set size, $B$, and effective lifespan, $L$, increase (set equal along x-axis), 
  social learning frequently evolves across an increasingly large range of
  environmental variability values, i.e., up to
  increasingly large values of the social learning ceiling
(y-axis; defined in Equation~\ref{eq:slCeiling}).}
  \label{fig:slCeiling}
  \centering
    \includegraphics[width=0.8\textwidth]{Figures/SL_ceiling.pdf}
\end{figure}


\subsection{Strength of selection}

\edit{To begin to confirm our interpretation of our analysis above, we measured
  strength of selection via the ensemble average of the number of
time steps to fixation over all simulation trials for a given parameter setting. More steps to fixation here indicates weaker selection.} Strength of selection is the extent to which the
social-learning trait provided agents with a consistent benefit. \edit{Selection
  strength is minimal when social and asocial learning
are equally beneficial.} 
% Even under consistent but weak selection pressure, drift can cause a population to take longer to reach fixation \citep{plutynski2007drift}. 
We denote the ensemble average over simultaion trials of the number of generations to fixation, denoted $\langle G \rangle$, where fixation means that the number of social learners, $\sum_i s_i$, is equal to either zero or $N$. %Indeed, social learning evolution and drift are reflected in the relative benefit of social learning to asocial learning.  

Figure~\ref{fig:steps} shows the average number of generations to fixation across all uncertainty parameters. Drift was greatest overall when payoff ambiguity was greatest, i.e., when $\pilow = 0.8$. When payoffs are highly ambiguous there is relatively little advantage to the optimal learning strategy, and therefore relatively weak selective pressure.

The average number of steps to fixation peaks at environmental variabilities 
where social learning goes from being favored to suppressed. 
Selection-set size, $B$, 
and payoff ambiguity, $\pilow$, 
had the clearest effects on which values of environmental variability maximized
the number of steps to fixation. As selection-set size and uncertainty were increased, 
social learning was favored for a greater range of environmental variability. 
% This pushes up the values of $u$ with greatest drift. 
Effective lifespan, $L$, 
had some effect on the location of peak time to fixation over environmental variability, 
but effective lifespan, $L$, had a more consistent effect on the
overall selection strength: $L=1$ trials took longer to reach fixation on average, 
especially when payoff ambiguity 
was low ($\pilow < 0.8$). However, the effect of lifespan on time to fixation was non-monotonic---longer
lifespans also resulted in longer times to fixation compared to intermediate lifespans (e.g., in
Figure~\ref{fig:steps}, top left and top right). When $L=1$, selection pressure may be relatively
weak since agents have no opportunity for individual learning, and social learning is the only
learning channel. When $L=8$ ($B=2,4$) or when $L=20$ ($B=10$), individual learning allows agents
many opportunities to find the optimal behavior, which means social learning provides a relatively
weaker constraint on net payoffs over agent lifespans. This would also results in weaker selection pressure since there is relatively little difference between social and asocial constraints when $L$ is large
(Figure~\ref{fig:steps}, top two rows).

\subsection{Relative benefits of social learning in context}

To check that populations evolved towards the learning strategy with higher expected payoffs, we also tracked the average net payoffs of agent populations across
all uncertainty parameters and compared these to the payoffs of homogeneous populations of all-social learners or all-asocial
learners. Average payoffs for the homogeneous populations were calculated by initializing simulation populations to be all-social or
all-asocial learners, running the model for 100 generations so payoffs could stabilize, and finally averaging the net payoffs from
the last generation across 1000 trials. Because simulations had no mutation, these homogeneous populations persisted as all-social
or all-asocial learners.

Figure~\ref{fig:payoffs} shows the average net payoffs normalized by lifespan
for our main simulation compared with the two reference homogeneous populations
initialized either as all-social or all-asocial learners. Often the simulated payoffs follow the payoffs of the better-performing homogeneous group. However, there are several important deviations worth explaining. First, populations sometimes evolved to be asocial learners, even
though all-social learner populations outperformed all-individual-learner populations when agents were
long-lived ($L=4$ and $L=8$) and in simple environments ($B=2$; e.g., Figure~\ref{fig:payoffs}A).
Second, we also observed the opposite dynamic: agents from our main simulations who evolved to be social learners sometimes outperformed agents in the homogeneous social learner populations. This is most pronounced when $L=1$, and even more
so when $\pilow=0.45$ and $B=10$ (Figure~\ref{fig:payoffs}C).
In fact, social learning evolved even in parts of the parameter space where the expected homogeneous social-learning payoff was lower than the expected homogeneous
asocial-learning payoff (Figure~\ref{fig:payoffs}B, e.g., $L=1$).

Our simulations' deviations from expected homogeneous payoffs reflect the effects of frequency-dependent payoffs and of stochastic environmental changes that affect geometric mean fitness. Frequency dependence is implicated in cases where our simulated agents that ended up as social learners outperformed homogeneous all-social-learner populations. In such cases, the earlier presence of asocial learners before social learning fixated enabled social learners in our simulations to outperform all-social learner populations. To illustrate the effects of stochastic runs of stable and unstable environments we inspected time series of individual model runs (Figure~\ref{fig:payoffTimeseries}). We plotted the geometric moving averages (time window = 3) of the payoffs for the whole simulated population, and for the simulated sub-populations of asocial and social learners. We compared these mean-payoff series to the expected homogeneous social and asocial payoffs, the time series of social-learner prevalence, and to the timing of environmental changes within the simulation (Figure~\ref{fig:payoffTimeseries}). 

When payoff ambiguity and selection-set size were small ($\pilow=0.1$ and $B=2$), and lifespan was long ($L \geq 4$), asocial learning fixated as a hedge against periods of protracted environmental instability, even though expected
homogeneous social payoffs were greater than homogeneous asocial payoffs (Figure~\ref{fig:payoffTimeseries}A). Runs of environmental change strongly affected the geometric mean fitness of social learners who were weighing
outdated information too heavily. \edit{In other words, environmental change lowers social learners' mean payoffs, but social-learner payoffs build back up as the information quality in the population improves (blue dots, Figure~\ref{fig:payoffTimeseries}A).  Even though a homogenous population of social learners would outperform individual learners in this case, unpredictable environmental stochasticity undermines the reliability of social learning.  When lifespan was minimal ($L=1$) and environmental variability was moderate ($u\approx0.5$), the opposite, unexpected outcome could occur where social learning fixates despite the fact that a homogenous population of asocial learners would outperform a homogenous population of social learners (Figure~\ref{fig:payoffTimeseries}B). In this case, it takes relatively few consecutive generations with environmental stability to attract the population to all become social learners.}

\begin{figure}
  \caption{Average number of generations (y-axes) to fixation. 
    Note the y-axis scale varies between plots, indicating different overall 
    time to fixation for different $(\pilow, B)$ combinations.} 
  \label{fig:steps}
\centering
    \includegraphics[width=\textwidth]{Figures/stepResultsPlots.pdf}
\end{figure}

\clearpage
\begin{figure}
  \caption{Comparison of observed average payoffs in simulations with average payoffs
    obtained by populations homogeneously initialized to be all social or all asocial learners. Often the simulated payoffs follow the payoffs from the better-performing homogeneous group, with some exceptions discussed in the main text.}
  \label{fig:payoffs}
  \vspace{1em}
  \centering 
    {\textsf A \quad Low payoff, $\pilow = 0.1$; selection-set size, $B = 2$} \\
    % \begin{subfigure}[]{0.4\textwidth}
    \begin{minipage}[]{0.4\textwidth}
      \centering
      \begin{rotate}{90}
        {\parbox{3.0in}{
            \centering
            % \vspace{-1.0em}\hspace{-1.5em} {\huge Low payoff, $\pilow = 0.1$} \\[1em]
            {\hspace{-7em} Mean payoffs, $\meanpi / L$}
        }}
      \end{rotate}%
      \includegraphics[width=\textwidth]{Figures/mean_prev_net_payoff_over_u_lowpayoff=0.1_nbehaviors=2.pdf}
      \\[-0.8em]
      {\centering \quad Environmental variability, $u$}
    \end{minipage} \\[1.5em]
    % \end{subfigure} \\[1.5em]
    \centering
    {\textsf B \quad Low payoff, $\pilow = 0.45$; selection-set size, $B = 4$} \\
    % \begin{subfigure}[]{0.4\textwidth}
    \begin{minipage}[]{0.4\textwidth}
      % {\large \textsf B}
      \centering
      \begin{rotate}{90}
        {\parbox{3.0in}{
            \centering
            % \vspace{-1.0em}\hspace{-1.5em} {\huge Low payoff, $\pilow = 0.1$} \\[1em]
            {\hspace{-7em} Mean payoffs, $\meanpi / L$}
        }}
      \end{rotate}%
      \includegraphics[width=\textwidth]{Figures/mean_prev_net_payoff_over_u_lowpayoff=0.45_nbehaviors=4.pdf}
      \\[-0.8em]
      {\centering \quad Environmental variability, $u$}
    \end{minipage} \\[1.5em]
    % \end{subfigure} \\[1.5em]
    {\textsf C \quad Low payoff, $\pilow = 0.45$; selection-set size, $B = 10$} \\
    % \begin{subfigure}[]{0.4\textwidth}
    \begin{minipage}[]{0.4\textwidth}
      \centering
      \begin{rotate}{90}
        {\parbox{3.0in}{
            \centering
            % \vspace{-1.0em}\hspace{-1.5em} {\huge Low payoff, $\pilow = 0.1$} \\[1em]
            {\hspace{-7em} Mean payoffs, $\meanpi / L$}
        }}
      \end{rotate}%
      % {\large \textsf C}
      \includegraphics[width=\textwidth]{Figures/mean_prev_net_payoff_over_u_lowpayoff=0.45_nbehaviors=10.pdf}
      \\[-0.8em]
      {\centering \quad Environmental variability, $u$}

    \end{minipage}
    % \end{subfigure}

    \begin{center}
       \includegraphics[width=.75in]{Figures/legendElements/dot.pdf}
       { Average all-social population payoffs}  \\[.725em]
       \includegraphics[width=.75in]{Figures/legendElements/ldash.pdf} 
       { Average all-asocial population payoffs} \\[.725em]
       \includegraphics[width=.75in]{Figures/legendElements/solid.pdf} 
       { Simulated average population payoffs} \\[.725em]
       { $\pmb{|}$  \quad $u$ value where homogenous social and asocial payoffs
      are equal} 
    \end{center}
\end{figure}


\begin{figure}
  \addtocounter{figure}{-1}
    \caption{Example time series of geometric moving average (GMA) with window of 3
      of payoffs from two select uncertainty settings (see main text), broken out by
    social learners, asocial learners, and whole population, compared with the
    expected homogeneous social and asocial population payoffs. Social-learner prevalence is also plotted. Vertical lines indicate environmental change.}
    \label{fig:payoffTimeseries}
  \centering    

\vspace{1em}
\hspace{-2em}

      \centering
      % \caption{$u=0.2$, $\pilow=0.1$, $B=2$, $L=4$}
      {\textsf A, Environmental variability $=$ 0.2, Low payoff $=$ 0.1, selection-set size $=$ 2, effective lifespan $=$ 4} \\
      \includegraphics[width=0.85\textwidth]{Figures/geopayoff_series/geopayseries_u=0.2-lowpayoff=0.1-nbehaviors=2-L=4.pdf} \\

    % \caption{$u=0.5$, $\pilow=0.1$, $B=4$, $L=1$}
      {\textsf B, Environmental variability $=$ 0.5, Low payoff $=$ 0.1, selection-set size $=$ 4, effective lifespan $=$ 1} \\
      \includegraphics[width=0.85\textwidth]{Figures/geopayoff_series/geopayseries_u=0.5-lowpayoff=0.1-nbehaviors=4-L=1.pdf}
    
\hspace{-2em}

% \hspace{-2em}
%     \begin{subfigure}[]{0.75\textwidth}
%       \centering
%       \caption{$u=0.2$, $\pilow=0.1$, $B=2$, $L=8$}
%       \includegraphics[width=0.95\textwidth]{Figures/geopayoff_series/geopayseries_u=0.2-lowpayoff=0.1-nbehaviors=2-L=8.pdf}
%     \end{subfigure}

\end{figure}


\subsection{Sensitivity analyses}

We performed sensitivity analyses to ensure that our main analysis was reasonably
robust to a range of auxiliary parameters. These sensitivity analyses are presented
in full in the supplemental material. First, we confirmed that our results were
robust to various population sizes $N$, though smaller-$N$ simulations demonstrated
weaker selection strength, as expected, due to stronger effects of finite population size (Figure~\ref{fig:populationSensitivity}). %, but  still generally support our main conclusions. 
Next, we verified model robustness to the number of prospective teachers, $N_T \in
\{2, 20\}$, to supplement the main results that used $N_T = 5$. The number of
prospective teachers did not change the results
(Figure~\ref{fig:nteachersSensitivity}), except to increase time to fixation when $N_T = 2$, since the benefit of social learning may be more difficult to detect with fewer prospective teachers (Figure~\ref{fig:nteachersSensitivity}a). Finally, we confirmed our results were reasonably robust to a wide range of softmax greediness parameters, $\beta \in \{1, 100\}$, to supplement the main results that used $\beta = 10$. However, when $\beta = 1$, an insufficient reliance on the best-paying behavior (i.e., low greed) caused agents to often ignore helpful social information  (Figure~\ref{fig:softmaxSensitivity}a). On the other hand, too much greed ($\beta=100$) made social learners inflexible so they could not recover as well when when they learned outdated social information. This cost to greediness was most pronounced for longer-lived agents who may spend several time steps performing a sub-optimal behavior (Figure~\ref{fig:softmaxSensitivity}b).

\section{Discussion}

 Despite the common claim that copying others makes sense when one is uncertain, we find that different forms of uncertainty can
 either promote or impede the evolution of social learning. By disambiguating various formalizations of uncertainty in a single
 computational model, we have developed a more nuanced theoretical understanding of how uncertainty affects the evolution of social learning. %(but see \citet{healy2017}).
%We reviewed and distilled several empirical and theoretical models in the literature along four uncertainty dimensions: temporal environmental uncertainty, selection-set size, ambiguous payoffs, and effective lifespan.  
We reproduced the well-known results that the uncertainty derived from a temporally-variable environment can limit the evolution of social learning if environmental change is simply too frequent for intergenerational transmission to be of value. Importantly, we also showed that this relationship is affected by other sources of uncertainty. 
%Our model reproduced classic predictions that social learning can yield higher payoffs than individual learning when uncertainty is sufficiently limited. 
We found that larger sets of behavioral options, shorter effective lifespans,
and increased payoff ambiguity could all favor the evolution of social learning.
However, these effects were not always straightforward. Increased payoff
ambiguity and decreased effective lifespan weakened selection strength
(i.e., evolutionary uncertainty in a finite-size population). Not surprisingly,
when the consequence of one's choice does not affect payoffs much, selection
either for or against social learning is substantially weaker. More
interestingly, selection is also weaker when the ability to learn individually
is fraught with uncertainty. Our model demonstrated that social learning can act
as a scaffold for \edit{adaptive} individual learning. We endowed agents with a
biologically-plausible individual learning mechanism \edit{based on a softmax decision rule}. This
enabled agents to recover from the potential cost of receiving outdated
information. This, in turn, enabled the evolution of social learning even when
social information was likely to be outdated. 

% \cm{this seems to say the opposite of the topic sentence. In topic sentence social learning-> asocial, but the mechanism descibed later is asocial learning -> social. Both seem possible, though the latter is easier for me to understand.}

Our modeling results suggest, on the one hand, that it might sometimes be better to
ignore social information from previous generations since our natural world is
rapidly changing~\citep[e.g.,][]{IPCC2022}. On the other hand, humans have increasingly more behavioral options (selection-set size) with high levels of uncertainty about which behaviors are most beneficial (payoff ambiguity), and in this case our model mostly predicts a greater prevalence of social learning.
In general, detailed theoretical models like this are likely to be critical for understanding how humans might adapt to an uncertain and rapidly-changing world.
%Such understanding could suggest plausibly beneficial interventions to mitigate existential threats~\citep{Moya2020,Jones2021}, especially in the most vulnerable communities~\citep{McNamara2020}, and to capitalize on new behavioral opportunities such as transitioning to clean energy use and production~\citep{NatureEnergyEditorialPromisesPremises2018,Brisbois2022}. However, to better identify potential pathways to effective adaptation it may be necessary to adjust some of our modeling assumptions to the cumulative nature of cultural evolution and group structure of interpersonal exchange, both of which affect the sustainability of novel adaptations~\citep{Derex2020,Centola2018,Smaldino2021a}.
%\cm{I guess I'd delete everything from "Such understandinc could suggest .... " It seems like such an implausible connectin and cheap talk, but others may disagree.} \mt{I gave this a try, with some restructuring to put the note about social learning as a scaffold for individual learning in the above paragraph.}

Our model necessarily made simplifying assumptions. These were chosen judiciously to
address the main question of how uncertainty affects the evolution of social
learning. Two critical assumptions we made have important consequences for comparing
our results with previous findings in the literature. First, we assumed all agents
engage in individual learning. This means that individual learning is effectively
free, though potentially inaccurate. Although producing new knowledge may be costly,
many other adaptive problems take the form of essentially cost-free individual
learning. For example, it is hard not to encode association between clouds and rain,
between thirst and drinking water, or between friendship and warm laughter.
\edit{If there were an exogenous cost of individual learning, this would likely
  increase the social learning ceiling across uncertainty parameter settings.
This means that our model does not capture the information-scrounging rewards to individual learning that produce mixed equilibria in precursor models \cite{Rogers1988}. Furthermore, our model operationalizes environmental variability as fully stochastic in a finite population. This makes it exceedingly unlikely for a heterogeneous population to persist since chance runs of very stable environments will lead to the extinction of asocial learners, while runs of very unstable environments will lead to the extinction of social learners. This further differentiates our results from precursor
models that allowed for persistent frequency
dependence of social learning benefit~\citep{BoydRicherson1985,Rogers1988,Feldman1996}.} Second, we only allow for
intergenerational social learning and environmental change. Within generations,
agents can only learn individually. This assumption \edit{is consistent with previous modeling work starting at least from \cite{Rogers1988}, and therefore} allows us to replicate the classic finding that if the environment changes too quickly, socially-learned information may become \edit{outdated. Adding horizontal social learning between vertical/oblique learning in this model would likely expand the range of environmental variability over which social learning would evolve~\citep{Turner2022}, i.e., horizontal learning would increase what we have called the social learning ceiling. However, depending on the
setting, there may be little difference between horizontal and oblique learning, for
example if the generations are purely cultural ‘generations’ where parents, and
others of the parent's generation, may also be peers.}

We could have made alternative choices for a range of other structural features, the future exploration of which
will be important to the development of more parsimonious theories of social learning.  
For example, we only considered success-biased learning, although people may use conformity or other context biases to socially learn~\citep{BoydRicherson1985,Muthukrishna2016a,Smaldino2018b}. This modeling
choice maximizes the potential benefit to social learners, which suggests that
other mechanisms, like conformity, may lead to \edit{weaker selection} overall. 
\edit{Furthermore, our social learning procedure could be interpreted as direct copying of latent psychological variables (expected payoffs for each behavior). Such detailed information is most likely transmitted through teaching wherein the model explicitly informs the learner of their experiences. If children learned instead from observations of the parent's behaviors without knowing rewards, which in some cases would be a more realistic assumption~\citep{Wu2022b}, this may weaken the strength of selection for social learning.} We also assumed that the number of behaviors and their payoffs were constant within a
given simulation, but this fails to account for evolutionary feedback which creates
new behavioral opportunities as time progresses\edit{~\citep{Chimento2022}}, e.g., via niche
construction~\citep{Smaldino2012a,Heras-Escribano2020} or cumulative cultural
evolution~\citep{Smolla2019,Derex2020}.  Group structure and processes such as
homophily and other group-level biases could inhibit the evolution of social
learning since successful out-group teachers could be cut off from in-group
learners~\citep{Golub2012}. We assumed agents choose behaviors via a softmax \edit{decision rule, which is more cognitively sophisticated than most social-learning models and captures the adaptiveness of real human learning mechanisms. This modeling decision was essential for developing our understanding of how social and individual learning can combine to multiply the problem solving capacity of our agents, though it is still a pale shadow of the true sophistication of human learning capabilities~\citep{Schulz2020a,Wu2022}}. More realistic and powerful individual learning could further support the evolution of
social learning. These considerations provide novel opportunities to expand the evolutionary theory of social learning by adding
such learning mechanisms to our model.

%\subsection{Conclusion}

%We found that the 
The evolution of social learning is a complex phenomenon, dependent on many interrelated factors, yet it is widespread across a
range of taxa. Although social learning is broadly studied, few studies have taken a systematic approach to understanding the role
of uncertainty in the evolution \edit{of} social learning. Understanding the role of uncertainty in social evolution is particularly important
for understanding human evolution as evidence increasingly suggests that the genus \emph{Homo} emerged in the context of substantial
(nonstationary) environmental variability \citep{anton_etal2014, levin2015}, and our global dispersal
\edit{meant} that human groups regularly faced novel environments. \edit{These
conditions and our longevity obviated the possibility of genetic
adaptation to specific ecological circumstances, requiring instead the evolution of
learning mechanisms for dealing with uncertainty. In our model, numerous behavioral
options led agents to be more cognitively flexible via the softmax decision rule, and
thus better able to adjust their behavior if social learning provided outdated
information. While Rogers'-style models of social learning evolution may also predict greater social learning reliance in more challenging contexts (larger selection-set sizes), these models rely on limited individual learning mechanisms that are furthermore mutually exclusive with social learning. This may prevent social learning from evolving under such high values of environmental variability as we observed here, even if these models included more adaptive individual learning mechanisms.} 
By carefully identifying and operationalizing different forms of uncertainty common in social-learning models, we developed a more thorough understanding of how uncertainty can favor social learning and how different forms of uncertainty interact to favor its evolution. By explicitly modeling a key individual-level learning mechanism shared across taxa, namely the ability to adjust behavior to uncertainty and new information, we found that social learning could evolve even if it provides outdated information. %Social learning is a critical component of problem solving among social creatures. Our work identified and systematized some important forms of uncertainty and catalogued their effects on the evolution of social learning.
Our work, then, both advances the theory of social learning and could eventually be of practical use in identifying specific mechanisms underlying adaptations to uncertain environments.


\paragraph{Supplementary material.} Supplemental analyses confirming model robustness to free parameters is available at \mt{OSF link to PDF when final and separated)}. Model and analysis code is publicly available on GitHub (\url{https://github.com/mt-digital/UncMod}), and the data used to make the figures presented here is available via OSF (\url{https://osf.io/t8exa/}).

\paragraph{Acknowledgements.} We thank colleagues at the Cultural Evolution
Society and Cognitive Science Society annual meetings in 2022 who provided helpful feedback
to presentations of this work. We also thank the editor and two anonymous reviewers
for helping to improve to the original manuscript.%\mt{Do we write any at this point? Please fill in as you see fit.} \cm{can do later since should be blinded anyway}
% 

\paragraph{Author contributions.} JHJ, CM, PES, and MAT conceived of the project. MAT developed the model
and analyses, with contributions from CM, PES, and JHJ. MAT implemented and analyzed the model. MAT wrote and edited the initial manuscript draft, which was extensively expanded and edited by CM, PES, and JHJ.

\paragraph{Financial support.} This work was supported by NSF grants BCS-2028160 and BCS-2118926 (JHJ PI) and awards from the Center for Innovation in Global Health and the Center for Existential Risk, Stanford University to JHJ.

\paragraph{Conflict of interest.} No conflict declared. \\[1em]

\bibliographystyle{apalike} %cite}
\bibliography{this.bib}


%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
\pagebreak
\begin{center}
  \textbf{\Large \textsf{Supplement}}
\end{center}
%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%
\setcounter{equation}{1}
\setcounter{figure}{0}
\setcounter{section}{0}
\setcounter{table}{0}
\setcounter{page}{1}
\makeatletter
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thepage}{S\arabic{page}}
% \renewcommand{\bibnumfmt}[1]{[S#1]}
% \renewcommand{\citenumfont}[1]{S#1}
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%




% \section{Additional main figure: Full net payoff comparison for all nine uncertainty conditions} 
% \ps{This should be part of the supplement. Also, all supplementary figures and tables should be preceded by ``S".}
% In the main text we showed a $2\times2$ array of plots comparing the observed
% mean net payoffs obtained by agents in our simulations, and in two auxiliary
% sets of simulations that set all agents to either have the social learning
% trait or not, which remained the case for the entire simulation since there
% are no mutations in this model (Figure~\ref{fig:payoffs}). Here we show the full $3\times3$ array of
% all $(\pilow, B)$ combinations shown for the main results. We see that
% populations of all social learners especially underperform initially mixed
% populations that evolve to be social learners 
% (Figure~\ref{fig:fullMeanPrevNetPayoffs}, bottom row). This highlights the
% importance of diversity for behavioral optimization, even if it is transient.


% \newpage



In this supplement we support our model conclusions by showing that our model
outcomes are stable over various settings of the three free auxiliary model
parameters: the number of agents ($N$), the number of
prospective teachers which social learner children compare
($N_T$), and the softmax behavior selection greediness parameter ($\beta$).
The results deviate only in minor ways from the main results primarily because of
\edit{weaker selection}
due to (1) finite population size effects (smaller $N$);
(2) lower quality of socially-learned information when agents can access fewer
prospective teachers (lower $N_T$); and (3) lower quality social information when $\beta$
was small (teacher agents would have explored non-optimal behaviors more
frequently, so their observed payoffs would have less probability weight in
the optimal payoffs on average). We give details below of model convergence, and
outcomes as we varied the three auxiliary parameters $N$, $N_T$, and $\beta$.

% \section{Expected payoffs}

\clearpage



\newpage

\section{Population size sensitivity analysis}

Drift was greater for smaller populations sizes, especially when $\pilow=0.8$, but 
the main patterns are robust with greater finite population size effects, specifically
with $N=50$ and $N=200$ (recall $N=1000$ tested in main analysis). 
Drift is also more pronounced for smaller $N$
for shorter lifespans, especially $L=1$. When $L=1$ and $N=50$ , the S-shaped
curve of $\meansl$ over $u$ becomes more linear with increasing $B$, 
with $\meansl$ values pulled towards \edit{neutral selection}, $\meansl \to 0.5$ (Figure~\ref{fig:populationSensitivity}a,
purple curves). With
$N=50$, all $\meansl$ over $u$ curves are flattened with less sharp transitions
from $\meansl = 1$ for lesser $u$ to $\meansl = 0$ for greater $u$. Despite
these finite-population effects, we still see the inhibition of social learning
as $u$ increases, more social learning across $u$ for larger $B$, and the
same complex \edit{selection-strength} effects for combinations of $\pilow$ and $L$ that interact
with $u$ and $B$ settings.

\clearpage

\begin{figure}
  \centering
  % \addtocounter{figure}{-1}
  \caption{
	Sensitivity analysis of the main results for two population
	sizes, $N=50,200$. Recall $N=1000$ was used to generate main 
	text results.
  }
  \label{fig:populationSensitivity}
  \begin{subfigure}{\textwidth}
	\caption{Population size, $N=50$}
	\includegraphics[width=\textwidth]{Figures/supplement/numagents=50/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}

\begin{figure}
  \ContinuedFloat
	\begin{subfigure}{\textwidth}
	  \caption{Population size, $N=200$}
	  \includegraphics[width=\textwidth]{Figures/supplement/numagents=200/mainResultsPlots.pdf}
	\end{subfigure}
\end{figure}


\clearpage

\section{Number of prospective teachers sensitivity analysis}

We found that the number of prospective teachers had little effect on $\meansl$
over $u$. There was slightly \edit{weaker selection} when $N_T = 2$ compared to our 
main text analysis, slightly \edit{stronger selection} than our main analysis when $N_T = 20$; 
we also tested $N_T=10$, which showed no obvious difference from our main results
with $N_T = 5$. When $N_T = 2$, \edit{weakened selection} is most pronounced in the
$\meansl$ curves when $\pilow=0.8$ (Figure~\ref{fig:nteachersSensitivity}a, 
bottom row). The transition from $\meansl = 1$ to $\meansl = 0$ is less sharp
across $L$ values, with social-learning evolution being suppressed beginning
at smaller values of $u$. By contrast, when $N_T = 20$, transitions from 
$\meansl = 1$ to $\meansl = 0$ are sharper across $L$ when $\pilow = 0.8$
(Figure~\ref{fig:nteachersSensitivity}c, bottom row). Otherwise, the main 
results were reproduced across all tested values $N_T=2,5,10,20$.

\clearpage


\vspace{-3em}
\begin{figure}
  \centering
   % \addtocounter{figure}{-1}
  \caption{Number of prospective teachers sensitivity analysis for $N_T=2,20$. Recall
  $N_T=5$ was used to generate main text results.}
  \label{fig:nteachersSensitivity}
  \vspace{2em}
  \begin{subfigure}{\textwidth}
	\caption{Number of prospective teachers, $N_T = 2$}
	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=2/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}
% \newpage
% \begin{figure}
%   \ContinuedFloat
%   \begin{subfigure}{\textwidth}
% 	\caption{$N_T = 10$}
% 	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=10/mainResultsPlots.pdf}
%   \end{subfigure}
% \end{figure}
\newpage
\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{\textwidth}
	\caption{Number of prospective teachers, $N_T = 20$}
	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=20/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}

\clearpage


\section{Agent greediness sensitivity analysis} 

We tested two additional settings of the softmax behavior selection greediness parameter,
$\beta=1,100$, which reproduced qualitative patterns in the evolution of social learning
observed in the main text where we used $\beta=10$.  
Formally, softmax greediness changes the 
probability mass allocated to selecting behaviors according to observed payoffs within that agent's
life history or learned from a teacher of the previous generation. 
Greater $\beta$ increases the probability that the optimal
observed behavior is chosen over all the rest, while smaller $\beta$ leads agents to explore alternative behaviors more frequently. If $\beta$ is too small, agents will fail to
fully exploit their knowledge about which behavior is optimal because they too frequently
explore less profitable alternatives.  If $\beta$ is too great the agents may prematurely
settle on a sub-optimal behavior because that is what they learned from a teacher, 
or because that behavior happened to pay off first. In a fuller evolutionary
exploration of model parameters one might allow $\beta$ to co-evolve, through
mutation and selection, with the social learner trait.  
Regardless, our sensitivity analysis shows our main conclusions of how social learning evolves under uncertainty remain unchanged for different $\beta$ over three orders of magnitude.

First, when $\beta=1$, most general trends are preserved, but in many cases the evolution
of social learning is suppressed, \edit{or selection strength weakens}, due to 
the overall poor quality of information acquired through softmax search-based
individual learning with this setting. \edit{Weakened selection} is especially pronounced 
when $\pilow=0.8$ since sub-optimal behaviors often pay off and $\beta=1$ is
not greedy enough to efficiently detect and exploit the optimal 
behavior (Figure~\ref{fig:softmaxSensitivity}a, bottom row).
Similarly, when $\beta = 1$, social learning is suppressed at much smaller values
of $u$ for longer lifespans, $L$, due to extended exploration of non-optimal
behaviors under this setting (Figure~\ref{fig:softmaxSensitivity}a, columns 
for $B$ and inset for $L$).

When $\beta=100$, our analysis again recovered general trends observed in the main analysis with
$\beta=10$ (Figure~\ref{fig:softmaxSensitivity}b). However, 
in some cases, especially when $\pilow=0.1$, social learning is suppressed compared to the main text results ($\beta=10$), because social learners may often greedily perform an outdated socially-learned optimal behavior over several time steps before possibly identifying the true optimal behavior (Figure~\ref{fig:softmaxSensitivity}b, top row).

\vspace{-3em} \begin{figure} %\addtocounter{figure}{-1} 
  \centering
  % \addtocounter{figure}{-1}
  \caption{Sensitivity analysis of the main results for the softmax parameter $\beta = 100$ and
  $\beta=1$. Recall the main results were obtained with $\beta = 10$.}
  \label{fig:softmaxSensitivity} \vspace{2em}
  \begin{subfigure}{\textwidth}
	\caption{Softmax greediness, $\beta = 1$}
	\includegraphics[width=\textwidth]{Figures/supplement/sensitivity_tau=1.0/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}

\newpage

\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{\textwidth}
	\caption{Softmax greediness, $\beta = 100$}
	\includegraphics[width=\textwidth]{Figures/supplement/sensitivity_tau=0.01/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}



\end{document}
