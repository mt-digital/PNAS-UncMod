\documentclass[letterpaper,11.5pt]{scrartcl}
\usepackage{totcount}
% \documentclass[11pt]{report}
% \documentclass{report}
% \documentclass{book}
\usepackage[bookmarks, hidelinks]{hyperref}
\usepackage{amssymb,amsmath}
\usepackage[title]{appendix}
% \usepackage{fullpage}
\usepackage{tabulary}
\usepackage{tabularx}
\usepackage{float}
% \usepackage[margin=0.50in]{geometry}
\usepackage[margin=1.00in]{geometry}
\usepackage[modulo]{lineno}
\linenumbers

\usepackage{booktabs}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{setspace}
\doublespace
% \usepackage{url}
\usepackage{bigfoot}
\usepackage[export]{adjustbox}
\setlength\intextsep{0pt}

% Colored comments 
\usepackage{color}
\definecolor{myorange}{RGB}{240, 96, 0}
\newcommand{\mt}[1]{{\textcolor{myorange} {({\tiny MT:} #1)}}}

\definecolor{myblue}{RGB}{30,144,255}
\newcommand{\jhj}[1]{{\textcolor{myblue} {({\tiny JHJ:} #1)}}}

\definecolor{mypurple}{RGB}{148,0,211}
\newcommand{\cm}[1]{{\textcolor{mypurple} {({\tiny CM:} #1)}}}

\definecolor{mygreen}{RGB}{26, 153, 51}
\newcommand{\ps}[1]{{\textcolor{mygreen} {({\tiny PS:} #1)}}}

\newtotcounter{citnum} %From the package documentation
\def\oldbibitem{} \let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citnum}\oldbibitem}

\usepackage{graphicx}
\usepackage{comment}

\usepackage{xcolor}
% \renewcommand{\linenumberfont}{\small\color{gray}}

%\title{The form of uncertainty affects selection for social learning}
\title{Different forms of uncertainty differently affect the evolution of social learning}

\author{{}}

\begin{document}
\maketitle

\newcommand{\pisub}[1]{\pi_{\mathrm{#1}}}
\newcommand{\pilow}{\pisub{low}}
\newcommand{\pihigh}{\pisub{high}}
\newcommand{\piI}{\langle \pisub{I} \rangle}
\newcommand{\piS}{\langle \pisub{S} \rangle}
\newcommand{\ledger}{\bar\pi_{ib}}

\newcommand{\meanvar}[1]{\langle #1 \rangle}
\newcommand{\meansl}{\meanvar{s}}
\newcommand{\meanpi}{\meanvar{\pi}}
\newcommand{\meansoc}{\meanvar{\pi_\mathrm{S}}}
\newcommand{\meanasoc}{\meanvar{\pi_\mathrm{A}}}
\newcommand{\meanT}{\meanvar{T}}
\newcommand{\meanG}{\meanvar{G}}

\newcommand{\bandit}{\text{Bandit}_b(0, 1)}

\begin{abstract} 
  Social learning is %essential to human survival---it 
  is a critical
  adaptation for dealing with uncertainty. However, uncertainty takes many forms.
  We identified four distinct and theoretically important types of uncertainty: temporal
  environmental variability, ambiguous payoffs, decision set size, and effective
  lifespans. We embed this framework in an evolutionary agent-based model to study conditions for the evolution of  social learning in populations with cognitively realistic individual learning
  capacities. % We used evolutionary agent-based modeling to track the evolution of social learning versus purely individual learning.
  %how often social, rather than individual,   learning evolved. 
  Agents could perform one of several behaviors, modeled as multi-armed bandit, to acquire payoffs.
  Individual learning used the softmax algorithm.  Social learning involved vertical and oblique transmission between generations, which served as a constraint on subsequent individual learning.  We found that different types of
  uncertainty had different effects. Temporal environmental variability suppressed
  social learning. Larger decision set sizes promoted social learning even
  when the environment changed frequently. Payoff
  ambiguity and lifespan had more complex effects on social learning, dependent on
  other uncertainty parameters.  This study shows the importance of clearly
  operationalizing uncertainty for understanding its role in social and cultural evolution.
% Social learning is essential to human survival. It is likely to evolve when it is more
% efficient than asocial, trial-and-error learning. Theoretically, social learning
% is adaptive for some uncertainty, but too much uncertainty makes
% social information unreliable. This fact is empirically
% supported across biology and human sciences. However, it is unclear how
% specific classes and types of uncertainty affect social
% learning evolution. Furthermore, existing models and experimental operationalizations of
% uncertainty are ambiguously related, and 
% tend to only consider a small number of behavioral
% choices.  Here we use evolutionary agent-based modeling to consolidate
% models of uncertainty in social learning evolution to address these issues.
% We model societies of agents who perform one of a number
% of possible behaviors to acquire payoffs in a time-varying environment.
% We identified complex patterns in social learning evolution depending on contextual
% uncertainty variables: environmental variability, ambiguous payoffs, 
% decision sets size, and effective lifespans. 
% Our work advances social learning evolution theory in a way that could help 
% guide human, non-human, and artificial intelligence towards optimal responses 
% to existential threats and new opportunities.
\footnote{This document contains
\total{citnum} references.}  
\end{abstract}


\section{Introduction}

Social learning enhances problem solving when acquiring information from others is more
efficient than learning on one's own~\cite{Laland2004}. However, social learning can also
lead individuals astray if they are copying irrelevant or outdated information.
Theoretical models have helped clarify the circumstances under which social learning
should be evolutionarily favored~\cite{BoydRicherson1985, aoki2014evolution,Kendal2018}, and these models have motivated empirical work that has both validated and refined theoretical predictions concerning social learning behavior in humans
and other species~\cite{galef2005social,McElreath2005,Kendal2018,Allen2019}.  This literature
indicates that social learning is a critical adaptation found across taxa for dealing
with uncertainty. When in doubt, copy others.  

Uncertainty weighs particularly heavily on human adaptation because of
our long lifespans, cosmopolitan societies, and dispersal across a highly variable environments, requiring coarse-grain and plastic behavioral adaptations \cite{levins1962}. However, the term ``uncertainty"
often conflates several different interpretations of that word. For example, different
models define uncertainty in terms of the rate of environmental change, spatial
environmental variation, or the reliability of information acquired from the environment.
Furthermore, in translating mathematical models to verbal predictions, the formal meaning
of terms like uncertainty is often lost \cite{knight1921, lawson1988probability, volz2012}, facilitating such
conflation. %Furthermore, it can be important to distinguish a narrower definition of uncertainty wherein the probabilities of outcomes remain unknown~\cite{knight1921,volz2012}. 
As the number of formal models of social learning have expanded, an ever
increasing number of modeling choices~\cite{Kendal2018} and formalizations of
uncertainty have made it difficult to compare across models or to consolidate our
understanding of the contexts in which social learning under uncertainty is adaptive. 
% Finally, while risk and uncertainty are often used interchangeably to refer to
% non-deterministic outcomes, 

%Other (asocial) forms of learning are also likely adaptations to uncertainty that should be accounted for, but are typically glossed over in models.  
In general, learning is an iterative
process during which an individual acquires information, forms representations and
predictions, and then tests and refines those representations and predictions to manage
uncertainty~\cite{jacobs2011bayesian,clark2013whatever}.  Because cultural evolutionary
models are often designed to explain \emph{social} learning mechanisms, they often contrast social learning with an overly simplistic mechanism for individual learning. In particular, it is often assumed that individual learners can \emph{always} pay a cost to learn the optimal behavior for a particular environment with certainty. This assumption implies that social learning by observing an individual learner is a good bet if the environment has not changed. Such modelling choices may lead us to overestimate both the extent to which individual learning provides
quality information and the value of social learning in a population of individual learners. % , both for asocially adapting to uncertainty and for social learners to take advantage of.
%and for the individual to adapt to the challenges assumed to be solved by social learning. 
% underestimate the quality of information
% available for social learning. 

To address these concerns we developed an evolutionary agent-based model that
simultaneously operationalizes several forms of uncertainty and endows agents
with a relatively powerful mechanism for individul learning. We model four kinds of
uncertainty that are common in cultural evolution models and the related empirical
literature:  (1) temporal environmental variability; (2) selection set size (the number of
possible behaviors); (3) payoff ambiguity (the difference in the expected rewards for
different behaviors); and (4) the effective lifespan of agents (the number of
opportunities for individual learning), explained below. In our model, social learners learn from the previous generation and asocial learners do not. All agents engage in individual learning within
their lifespans. The model also assumes a more
cognitively realistic and empirically-motivated learning mechanism, the softmax algorithm, which allows  learners to make full use of the available data acquired by both individual and social learning. 
Our model design thereby affords us a richer and possibly more accurate assessment of tradeoffs between 
social and asocial learning. 
We use this integrated model to ask which kinds of uncertainty are likely to favor social learning and to clarify the logic underlying the results.
%of why this would be the case.  
In the remainder of this introduction we briefly review previous research on both the forms of uncertainty and the learning mechanism used in our model. 
%We then present how our evolutionary agent-based model works. Finally, we explain the logic underlying the result that different forms of uncertainty can either suppress or encourage the evolution of social learning. 

%% \cm{from Jamie's intro, not sure we should incorporate the rest here since our model doesn't speak much to things like heavy tailed distributions or adaptive toolkit work: Despite the technical difficulties of dealing with uncertainty, addressing it is an essential task because it potentially changes our understanding of decision-making in a qualitative manner. The dominant approach to understanding decisions for choices with variable outcomes is expected utility theory (EUT). As the name suggests, EUT requires the ability to calculate expectations, which means that we must know the probability distributions of outcomes. The non-probabilistic nature of uncertainty means one cannot calculate expectations. Following \cite{savage1954}, various research traditions in decision theory and economics have treated uncertainty as if it were risk, just with subjective probabilities replacing objective ones. The fundamental problem with this approach was noted by \cite{geweke2001} and further developed by \cite{weitzman2009}. In particular, the probability density function of an outcome that needs to be learned, but for which opportunities for learning are highly constrained, will be heavy-tailed and expected-utility calculations will not work because of the resulting undefined mass-generating function. Uncertainty implies heavy-tailed probability distributions and heavy-tailed distributions require different analytical methods \cite{nair_etal2022}....para...The heuristic-based adaptive-toolbox approach of \cite{todd_gigerenzer2000} provides an alternative strategy for understanding decision-making under uncertainty. There is a strong intuition that uncertainty should activate specific social-learning heuristics. Within the cultural-evolution literature, uncertainty is generally thought to lead to a social heuristic known as \emph{conformist-biased learning} \cite{boyd_richerson1985, henrich_boyd1998, muthukrishna_etal2016}....para...True uncertainty arises when an organism lacks the capacity to learn about the possible outcomes of a decision task. This is very likely for a cosmopolitan species living in a coarse-grain environment. Task complexity also. Non-stationary environmental change \cite{kay_king2020}. These potential sources of uncertainty can also interact.}




% \cm{I moved this for now: \emph{"Furthermore, many models of social learning evolution do not account for individual-level cognition~\cite{Heyes2016}, though humans clearly have evolved cognitive mechanisms for dealing with uncertainty generally~\cite{Gershman2019,Schulz2019}."} because I think it interrupted the flow and didn't seem directly linked to the goal of understanding aspects of uncertainty. However, if this is one of the main features of the model that we want to highlight as an improvement over previous work, then we probably have to say something more about it. Perhaps I just wasn't seeing the connection though, and the more accurate cognitive model DOES add to our ability to study the consequences of uncertainty. If that's the case, the argument should be sharpened. If not, maybe we put this info when the cognitive model is introduced.}\mt{Agreed. I put a first draft of a better version of this paragraph closer to/at the end of the Intro.}


%\mt{This paragraph is a first try to introduce the four uncertainty dimensions with examples to illustrate the problem we are answering. I outlined the next paragraph to get into more details of social learning: how cultural evolution works; conformity, success-biased, etc. Cristina, please edit this.} 

\subsection{Varieties of Uncertainty}

Uncertainty involves a reduced ability to predict what will happen in the future or to assess which actions are likely to yield particular outcomes. Uncertainty can manifest in many ways. We focus on the following four sources of uncertainty for the evolution of social learning: (1) temporal environmental variability, (2) selection set size, (3) payoff ambiguity, and (4) effective lifespan.

\textbf{Temporal environmental variability.} When environments change
(for example, in response to climatic events, migration, or technological paradigm shifts),
strategies that were previously adaptive may no longer be optimal. The difficulty
in predicting either when such shocks will occur or which behaviors will be
adaptive in the resulting environments leads to uncertainty. 

Temporal environmental variability is fundamental to most evolutionary models of
social learning. Such fluctuations have been proposed as an important selective
pressure for learned as opposed to genetically fixed behaviors when genetic adaptation cannot keep pace with environmental change 
~\cite{Richerson2000}. On the other hand, environments that change \emph{too} quickly
will select against social learning so that individuals avoid learning outdated--- 
and therefore maladaptive---information~\cite{Feldman1996,
BoydRicherson1985}. This suggests that intermediate levels of temporal variation
are important for the evolution of social learning mechanisms~\cite{aoki2005}.

%Despite the theoretical centrality of t
Temporal environmental variability tends to be modeled in one of 
several ways~\cite{aoki2014evolution}. Most commonly, it is modeled
as an independent probability that the environment changes its state (and its corresponding optimal behavior) before each new generation
~\cite{BoydRicherson1985,Rogers1988,Feldman1996,McElreath2005,Enquist2007,perreault2012bayesian,aoki2014evolution}, but
% The probabilities of environmental change are usually fixed per generation
%~\cite{BoydRicherson1985,Rogers1988,kendal2009evolution}, 
it has also been modeled using deterministic cycles, so that environments repeat at regular intervals ~\cite{Feldman1996, aoki2014evolution}.
%Furthermore, t
The consequences of environmental change can range from mild to
catastrophic. In the latter case, a change of environment results in the total
elimination of any adaptive behavior, which must be learned \emph{de novo} for the
new environment~\cite{Rogers1988}. Such catastrophic environmental changes present
a large adaptive challenge as individuals cannot rely on accumulated information
from previous generations. Other models of environmental change introduce less
uncertainty as they fluctuate between two or more environmental states with corresponding
adaptive behaviors. This means that previously maladaptive
behaviors become adaptive when the environment changes
~\cite{perreault2012bayesian}. The chosen mechanism for modelling temporal
change has important theoretical consequences, reviewed in Aoki \& Feldman (2014).~\nocite{aoki2014evolution} Our study design ignores cases where temporal variation is low enough that genetic selection can canalize a behavior, and instead considers only behaviors that can be learned. 


\textbf{Selection set size.}
When one does not know which option to take, uncertainty increases with the number of options, which we call the selection set size.
% This is a mathematical fact at the
% core of information theory: the number of bits required to reliably encode the optimal solution increases by one every time the
% selection set doubles in size~\cite{mackay2003information}. 
% This is intuitive; the more options to consider, the greater one's uncertainty about which option is the best choice. 
In many studies of social learning, the selection set is often limited to just two options.  For example, in empirical studies of \emph{bombus
terresteris} (bumble bee)~\cite{Baracchi2018} and \emph{parus major} (great
tit)~\cite{Aplin2017}, experimenters provided two behaviors from which the bees or birds
could choose, with one yielding a higher payoff than the other. %respectively,
%each yielding greater or smaller payoffs depending on experimental treatment.
Similarly, many human studies have used just two or three possible
behaviors~\cite{McElreath2005,Morgan2012, Toyokawa2019}. Behavioral study designs are
often motivated by modeling studies with similar formulations~\cite{Rogers1988,boyd1995does,Feldman1996,
perreault2012bayesian}.
% \cm{pretty sure boyd1995 uses same trick as
% rogers 88 so not sure why they were being used as illustrating separate kinds of
% behavior selection sets. correct if wrong} 
Larger, more open sets of behavioral
choices are not uncommon in experiments trying to capture more complex or
naturalistic tasks~\cite{derex2013, wasielewski2014}, but these map on
imperfectly to the theoretical literature that tend to use a limited set of behavioral options.
%\mt{How so?}. 
Some models have studied systems with
larger, but defined, selection sets~\cite{Rendell2010, lindstrom2016co}, while in others the
number of options is subsumed under the probability that a learner gets the right answer~\cite{Feldman1996,Enquist2007}.
%\mt{How does this work exactly in Enquist et al 2007?}. 
%Researchers have also compared models with a different number of environment states, corresponding to a different number of optimal behaviors through time~\cite{Feldman1996}. 
Rarely if ever is the size of the selection set explored explicitly as a source of varying uncertainty, even though the number of options one has is likely to increase with the difficulty of the decision task~\cite{haynes2009testing,white2009testing}.  
%These examples share one common feature: the size of the selection set was held static \emph{within} model generations.
% as a measure of changing uncertainty in cultural evolutionary models.

\textbf{Payoff ambiguity.} Most models of social learning necessarily differentiate between the payoffs for adopting optimal vs. non-optimal behaviors
\cite{BoydRicherson1985,Rogers1988,Enquist2007,Rendell2010,aoki2014evolution}. The size of the difference between
these payoffs is usually taken to indicate the strength of selection of learning. %, which makes sense. 
However, the ability to discern payoff differences between behaviors is also a source of uncertainty. In reality, payoffs for particular behaviors are not always consistent. A behavior may yield a large payoff sometimes and a small
payoff other times \cite{McElreath2005}. This means that signals about the
relationship between behavior and payoff are often noisy, and differentiating
between behavioral options is in part a problem of signal detection.  When the
difference in expected payoffs between optimal and non-optimal behaviors is very
large, this noise matters little, as the signal is still very clear. However, when
the expected payoffs of different behaviors are similar relative to the size of
their variances, ambiguity arises about which behaviors really are superior.
Smaller differences between payoffs corresponds to larger ambiguity. Payoff
ambiguity has been manipulated in both theoretical~\cite{perreault2012bayesian}
and empirical~\cite{McElreath2005, Morgan2012} studies, both of which support the
claim that payoff ambiguity increases the reliance on social information.
Importantly, payoff ambiguity %differs from selection set size in that it not only 
affects both 
%affects uncertainty, it also directly influences both 
uncertainty \emph{and} the
strength of selection, with smaller payoff differences leading to greater uncertainty for a learner and weaker evolutionary selection favoring optimal strategies. %This parameter sometimes takes the form of differences in
%expected payoffs arising from different behaviors or strategies~\cite{Enquist2007,Rendell2010} or by varying the standard deviation of payoffs~\cite{McElreath2005}. 

\textbf{Effective lifespan.} 
The more opportunities one has to learn during one's lifespan, the more uncertainty can be reduced, assuming a
static environment. Correspondingly, a reduction in the number of opportunities to learn will increase the uncertainty about which behavioral options are available and what their associated
payoffs are. %Such uncertainty can be passed on to future generations.
% Learning is an iterative process by which one repeatedly acquires information, forms
% representations and predictions, and tests and refines those representations and
% predictions to manage uncertainty \cite{jacobs2011bayesian,clark2013whatever}. 
We refer to the number of learning opportunities as an individual's effective lifespan to highlight that it is the number of opportunities to learn about the payoffs associated with a behavior, rather than the number of sunrises one experiences, that determines the level of uncertainty present in one's choices.  
%throughout the individual's lifespan that matters here, not necessarily how long they live in the absence of relevant learning opportunities.  

Empirically, the number of learning opportunities can be manipulated in the lab, and in the real world will tend to correlate with an individual's relative age. In multi-round
studies of information use in novel tasks, US participants' use of social
information declined precipitously across rounds~\cite{McElreath2005}, suggesting
they were more likely to use social information when they were most uncertain about the task early on. In a more naturalistic context, Aplin et al. (2017)
\nocite{Aplin2017} found that younger great tits more readily used social
information compared to older individuals, possibly because they had accrued
less information via individual learning, and possibly because younger
individuals have the most to gain (given their expected remaining lifespan) by switching to superior behavioral options. 
% \ps{I got rid of the Leris and Reader reference because it didn't seem relevant
% to age-based uncertainty. They just showed that young guppies exposed to
% reliable models were more likely to use social information later. I also added
% some human studies, which seems important.} 
Cross-cultural studies have highlighted the importance of childhood as a phase
of heavy social learning in humans ~\cite{Reyes2016}. Young children are more likely to
acquire their beliefs and simple skills from their parents than are older children
or adults, which is at least partly due to the differential knowledge accrual
between young children and the older adults to whom they direct the most trust and
attention \cite{kline2013teaching}.
%The age of individuals was found to have an effect on social learning in both
%\emph{parus major}~\cite{Aplin2017} and \emph{poecilia reticulata}
%(guppies)~\cite{Leris2016}. \ps{What effect? I'm not sure } \mt{Need better
%connection between lifespan and age, or better references to support use of
%lifespan}.
The effective lifespan for learning
varies across tasks, individuals, and species, yet most models assume only one learning
opportunity per generation~\cite{BoydRicherson1985, Feldman1996,Henrich1998, perreault2012bayesian}.
Some models do allow several cultural generations within one genetic generation
~\cite{Enquist2007,Rendell2010,lindstrom2016co}, but little formal theory explicitly examines the role of
learning opportunities in the evolution of social learning. 

%To answer our research questions about the combined effect of various forms of uncertainty on social learning evolution, we developed an agent-based model that incorporates all four of these uncertainty variables. We systematically vary these parameters to understand and predict their effects on social learning evolution.

% \subsection{Other adaptations to uncertainty} 
\subsection{Individual-level adaptations to uncertainty} 

% \begin{comment}

% \cm{I think a lot of this may be too much detail. I'm still editing and focusing the above on the main forms of uncertainty we are modeling and reviewing the relevant literature as we go. Yes we've made choices about things like horizontal vs vertical, but i think we can just justify that when we introduce the model }
% ps{I agree with Cristina here. I think we should use this section to justify our way of modeling individual and social learning, which is different from previous models. We don't need to provide a detailed review, just why it's worth doing it as we've done it. In particular, we should set up (1) social learning as an initial scaffold for future social learning, and (2) softmax individual learning which involves some greediness with occasional trial and error.}

% To add to confusion about how to integrate diverse models of social learning
% evolution, different models select different social learning components in
% seemingly \emph{ad hoc} ways 
% \begin{itemize}
%   \item 
%     Vertical, oblique, horizontal transmission
%   \item
%     Conformity, payoff-biased, frequency-dependent, etc. A note about how
%     ``conformity'' is often not distinguished from other forms of social learning
%   \item
%     Review human studies
%   \item
%     Review non-human studies~\cite{Leris2016,Aplin2017,Avargues-Weber2018,Baracchi2018}
%   \item
%     One sentence on how dual-inheritance theory enables us to gloss over whether
%     social learning is genetically or culturally evolved.
%   \item
%     More things from which we selected the operation of our model
% \end{itemize}

% \end{comment}

%Social learning is the adaptive icing on the cake of other cognitive adaptations to ecological uncertainty. 
While the literature reviewed above suggests that
several forms of uncertainty have played a role in the evolution of social
learning, other cognitive mechanisms have likely also evolved in response to
uncertainty~\cite{volz2012,johnson2013evolution,van2018uncertainty}. Many of these are flexible learning mechanisms that
do not require imitating the behaviors of others. For example, when faced with greater uncertainty individuals may adopt more exploratory learning strategies and may even preferentially test behaviors with greater observed payoff variance 
\cite{Wilson2014,Gershman2019}.

Many models of social learning simplify by using minimally cognitive %assume little to no cognitive capabilities of their 
agents. For example, a common modelling strategy compares the payoffs of
agents with different pure learning strategies (e.g., those who only engage in social
learning versus those who only engage in individual learning) while revealing nothing about the
cognition underlying individuals' decisions~\cite{BoydRicherson1985, Rogers1988,
aoki2005}. This sort of behavioral gambit is common in evolutionary modeling, but has also been criticized as `blackboxing' key cognitive processes that are important to social and cultural evolution \cite{Heyes2016,Kendal2018}.  
Some more complicated learning strategies that make use of both socially and individually learned information have been studied ~\cite{Enquist2007, perreault2012bayesian}, including those that integrate cognitively plausible mechanisms such as reinforcement learning \cite{lindstrom2016co}, though the latter approach remains the exception rather than the norm. 
%but these are seldom designed to reflect cognitive mechanisms for integrating information. Though such simplifications are often useful, several authors have warned of the risks to \emph{blackboxing}, or ignoring, cognitive mechanisms \cite[p. 658]{Heyes2016, Kendal2018}, given such details may be theoretically meaningful. 
In order to understand how social learning evolves as an adaptation to uncertainty, we 
endowed agents with a biologically plausible cognition capable of integrating information from various sources to maximize payoffs, using \emph{softmax
search}~\cite{Gershman2019}, described in more detail below. 
% \cm{I don't
%   understand this next sentence, but think it can be cut with no loss of meaning:
%   In our model we do not impose any structure in randomness between behaviors, so
% our cognitive model is only sensitive to total randomness.} 
% To do so, we let
% agents see the payoffs to behaviors and use the softmax function to convert these
% observations to a probability distribution from which they strategically select
% their own behavior. %\cm{does this still make sense? and does it need a citation?}

%\paragraph{Meaning of uncertainty in ecology (and cognitive and social sciences?) } (JAMIE, PAUL?) \ps{I've added a bunch to the section on different types of uncertainty, which could be more fleshed out if we like. I don't think an additional section here is needed.}
%We need to support our claim that these four classes of uncertainty really count as forms of uncertainty and show how it is consistent across ecology, and maybe connect to uncertainty in cognitive and social sciences more broadly. 

%\paragraph{Evolutionary ABMs for social learning evolution theory development} (PAUL)
%\ps{I'm not sure a section is needed on this, but we can add something about how ABMs allow us to capture complexity not possible with purely mathematical approaches. I think it probably makes the most sense to address this at the beginning of the model description.}

\section{Model}

% \cm{Other choices we made that might need to be justified: 1) softmax: existing models underestimate the power of learning from experience by not having a rich cognition. This rich cognition can improve both individual learning and help social learners recover from outdated / misleading social info. 2) no conformism: but that's ok because we're giving social learning the best chance of success. 3) no horizontal transmission, no spatial variation}

%To understand how uncertainty affects social learning, we developed an agent-based model of social learning evolution.  Evolutionary agent-based models simulate changes in the prevalence of a phenotype over several generations---in this model the phenotype is whether or not an agent engages in social learning.  
In our model we allow just one trait to evolve; social learning, while all other parameters are exogenous. Our primary outcome measure is the overall frequency of the social learning trait at the end of each simulation, and we study how this prevalence responds to the four varieties of uncertainty considered in this paper. 

A population of $N$ individuals each must decide which of $B$ behaviors to perform at
each time step within a generation consisting of $L$ time steps. The behavior set is a multi-armed bandit with $B$ arms, that is, agents can pick one of $B$ behaviors with random-valued payoffs~\cite{SuttonBartoBook,McElreath2005,Steyvers2009,Rendell2010,Schulz2019}.  
In each generation, exactly one behavior is more likely to pay off than all the rest and is therefore optimal. Agents
optimize their net payoffs over their lifespan by quickly figuring out which
behavior is optimal and performing it as often as possible within their lifespan.
%The optimal behavior is static within agent lifespans, but varies in general between generations, representing environmental variability.
At the end of each
generation, agents are selected with replacement to reproduce a new generation of $N$ agents,
with the probability of reproduction biased by net payoffs. Agents who inherit the social
learning trait learn about payoffs from the previous generation, while asocial learners begin
life only knowing the number of behaviors the environment affords, but no knowledge
of behavioral payoffs.
\cm{or would you consider having flat priors over all behaviors knowledge?} 
\mt{I changed this last sentence to express that they have flat priors, in somewhat different
terms.}
%The specifics of the model construction and dynamics are described in detail below.
% \ps{I cut a bunch of stuff that came right here as being redundant or unnecessary.}

% We operationalize four separable varieties of uncertainty that affect the
% ability of agents to find and choose the optimal behavior: 
% \emph{environmental variability}; 
% \emph{selection set size}; \emph{payoff ambiguity}; and the \emph{effective lifespan}. 
% %Environmental variability is the probability that the optimal behavior changes
% between generations.   
% % This is empirically justified since cultural evolution
% % occurs when meta-cognitive strategies and information are transferred via
% % learning and social influence, instead of by physical reproduction and death
% % as in genetic evolution.  
% The selection set size is the total number of possible
% behaviors agents choose from, assumed to be constant within a simulation.  
% Payoff ambiguity is the payoff difference between optimal
% and non-optimal behaviors. The effective life span is the
% number of time steps in which agents perform behaviors within a generation. 
% Our model is not spatial, so agents have free, instant
% access to all behaviors, and there is no spatial uncertainty. 
% These conditions reflect humans in a computer-based social learning evolution
% experiment~\cite{McElreath2005,Morgan2012,Derex2016}. Spatial dimensions could also be
% considered irrelevant if costs associated with accessing a behavior were equal,
% e.g., if it was assumed to be equally costly for animals to
% visit alternative food sources~\cite{Aplin2017,Baracchi2018}.
% Each simulated environment provides a distinct challenge
% to the agents, which will lead agents to differently evolve to become social
% learners or not, depending on which strategy optimizes net payoffs.

% \emph{Agents} here are autonomous, intelligent, simulated problem solvers. Each
% agent evaluates its environment and chooses how to act within that environment based
% on a set of empirically-motivated rules.  Our agents select which behavior to do
% probabilistically, weighted by the softmax function applied to the mean payoff they
% have observed for each behavior. The softmax function is a biologically plausible
% generalization of behavior selection under uncertainty that enables agents to often
% greedily exploit the most lucrative behavior (based on their observations) but also
% to sometimes explore alternatives~\cite{Schulz2019,Collins2013,Daw2006,Yechiam2005}.
% Such individual-level intelligence is a critical adaptation that has 
% co-evolved with the capacity for social learning. We will show that individual
% learning can support the evolution of social learning.

% In our \emph{evolutionary} agent-based model, agent life cycles are
% programmed to cause agents to reproduce and die off, where reproducers pass on
% heritable traits to their offspring. 
% Natural selection occurs in the model when agents with higher
% payoffs preferentially reproduce. This is a model of cultural evolution, so
% ``reproduction'' means teaching the meta-cognitive strategy of whether one should learn
% socially at all; ``death'', in this interpretation, means
% loss of the potential to socially influence others. 
% This sets up an inter-generational cultural structure
% that we also use as a scaffold for \emph{oblique} social learning, meaning children
% with the social learning trait learn about payoffs from a member of the
% previous generation. Evolution acts as an optimization routine to identify
% whether individuals with the social learning trait will outperform those without.  

% Agents inherit one trait in this model, whether or not
% an agent, $i$, learns socially. If $i$ has the trait we write $s_i=1$
%  and 0 otherwise. In our analysis, we 
% average $s_i$ over all agents and simulation trials to understand the affects of
% different uncertainty parameter settings. 
% Our computational analysis is based on observing and comparing patterns in
% aggregated $s_i$ across different parameter settings, 
% supported by measuring the number of generations 
% to model convergence and expected payoffs in populations across the same contexts. 
% To understand how different varieties of uncertainty interact
% to affect the evolution of social learning, we systematically created an array of
% simulated environments by systematically varying the uncertainty parameters, and
% auxiliary model parameters to ensure model validity. 


\subsection{Model environment and uncertainty}

%The model environment provides behaviors for agents to perform. 
The structure of the environment is specified by several parameters that remain fixed throughout the course of a given simulation (Table~\ref{tab:uncertaintyParameters}).  %including three of the uncertainty parameters: environmental variability, selection set size, and payoff ambiguity. 
The environment affords $B$ behaviors, where
$B$ is the \emph{selection set size}.
%, but varied systematically across simulations.
Each behavior is indexed by $b$ and 
%modeled as a ``one-armed bandit'', which 
yields a payoff 
%Bernoulli-distributed payoffs 
of 1 with probability $\pi_b$ and a payoff of 0 otherwise. % with probability $1 - \pi_b$. 
$\pi_b$ is equivalently the expected
payoff of behavior $b$.  
At the beginning of each generation, one behavior is optimal and yields expected
payoff $\pihigh$; the other $B-1$ behaviors yield a lower payoff, $\pilow$. 
The \emph{payoff ambiguity} is defined by $\pihigh - \pilow$. 
We fix $\pihigh = 0.9$ to be constant across all simulations, so 
payoff ambiguity is varied by changing the value of $\pilow$. In other words, payoff ambiguity increases with $\pilow$.  Agents have $L$ timesteps to learn and act per generation (i.e., the \emph{effective lifespan}). Uncertainty decreases with $L$. At the start of each generation a new optimal behavior is selected at random from the set of all possible behaviors with probability $u$ (the \emph{environmental variability}), otherwise the optimal behavior remains unchanged from the previous generation. 


\vspace{2em}
\begin{table}[h]
\caption{Environmental parameters used in our simulations, including uncertainty parameters $u$, $B$,
$\pilow$, and $L$. Bold indicates default value tested} %\emph{default value tested}.}
    \label{tab:uncertaintyParameters}
    \centering %\hspace{-3em}
    \begin{tabular}{cp{4.0in}p{1.25in}} \toprule

        Symbol & Description & Values tested \\ 

        \midrule  

        $u$    & Probability optimal behavior changes between generations 
               & 0.0, 0.1, \ldots, 1.0 \\

        $B$       & Number of behavior options
                  & 2, 4, 10 \\

        $\pihigh$ & Probability that the unique optimal behavior pays off 1 
                & \textbf{0.9} \\

        $\pilow$ & Probability one of $B - 1$ non-optimal behaviors pays off 1 
                 & 0.1, 0.45, 0.8 \\ 

        $L$    & Time steps per generation & 1, $B/2$, $B$, $2B$, $4B$ \\

        $N$    & Population size
                 & 50, 100, 200, \textbf{1000} \\
               
        \bottomrule
        \end{tabular} 
\end{table}



\subsection{Agents and learning}

%Agents are endowed with dynamic attributes to intelligently select behaviors and calculate average payoffs for each behavior. 
Agents either exclusively rely on asocial learning or additional use social information. For simplicity, we refer to the latter as social learners. Learning strategies are assumed to be heritable traits. Each agent $i$ has a learning trait $s_i$, which is 1 if $i$ is a social learner and zero otherwise. Every agent engages in
individual learning over its lifespan, regardless of learning strategy.
Social learners begin life with
behavioral preferences based on information from an agent chosen  from the previous generation. 
Asocial learners begin life with no behavioral
preferences. Agent-level parameters are described in Table~\ref{tab:modelParameters}. 
% Agents and their learning procedures are specified through several
% parameters introduced below.


\subsubsection{Individual learning}

All agents perform individual, trial-and-error learning at each time step in
their lifespan.  Learning is guided by softmax search. Softmax search
guides agents to more frequently exploit the most profitable behaviors when the
agent is more certain which is optimal and to explore more frequently when the
agent is unsure.  To do softmax searching, agents track average payoffs acquired
from each behavior they have performed and the number of times they
have performed each behavior. \cm{is the previous sentence still right? I changed it's meaning because it made it sound like tracking average meant keeping track of total number of times it was performed, but that's not inherentely the case. Softmax does BOTH right? to estimate certainty.}  We denote the average payoffs obtained by agent $i$
for behavior $b$ as $\ledger$. We denote the number of times $i$ performed $b$
as $c_{ib}$ (``$c$'' stands for count). 
At each time step, agent $i$ performs behavior $b$ with softmax-weighted probability
\begin{equation}
  \Pr(\text{Agent $i$ performs behavior $b$}) = 
    \frac{e^{\beta \ledger}}{\sum_{b=1}^B e^{\beta \ledger}}.
\end{equation}
\noindent
$\beta$ adjusts how frequently agents perform 
behaviors with high expected payoffs (larger $\beta$) versus how frequently
agents explore alternative behaviors (smaller $\beta$). %~\cite{McElreath2005}. 
We used a default value of $\beta = 10$, but also varied this value in our sensitivity analyses. 
The softmax function used here is a biologically plausible
generalization of behavior selection under uncertainty that enables agents to often
greedily exploit the most lucrative behavior (based on their observations) but also
to sometimes explore alternatives~\cite{Schulz2019,Collins2013,Daw2006,Yechiam2005}.


\subsubsection{Social learning}

At the beginning of each generation other than the first, each social learner selects
one member of the previous generation to learn from in a payoff-biased way. 
%, if the child inherited $s_i = 1$. A child agent $c$ is a social learner if its parent $p$ was a social learner, i.e.\ $s_c \leftarrow s_p$, without mutation.
A social learner  
selects this ``teacher" from the previous generation by first selecting $N_T$ prospective teachers at random, then selects its teacher from this set with a probability weighted by each prospective teacher's net payoff 
relative to the other $N_T - 1$ prospective teachers. The social learner then inherits information about the likely payoffs of each behavior from the teacher, whereas asocial learners do not acquire this information. \cm{I think this inheritance has to be explained more. (I see that you do this later, so maybe it can be cut back here)} In this way, the social learner can potentially reduce the amount of exploration needed to both execute and learn about the optimal behavior.  


% \subsubsection{Social learning as a scaffold for individual learning}

% In this model, being a social learner is beneficial when it is more likely on
% average to provide greater net payoffs than being an individual learner.  It is not
% catastrophic for an individual to receive outdated information, as is sometimes
% assumed~\cite[e.g.]{Rogers1988}. Instead, agents explore alternatives and
% greedily perform different behaviors that pay off better. 
% This mechanism is critical for explaining the patterns we observe in the 
% Analysis, where social learning evolves when $u > 0.5$.
% In this case, the optimal behavior will switch between generations more often than
% not. Without individual learning, social learning would not evolve when $u > 0.5$.

\begin{table}[h]
  \vspace{2em}
  \caption{Agent-level variables. The first four ($\protect s_i$, $\protect
    \bar\pi_{ib}$, $\protect c_{ib}$,
  and $\protect \pi_i$) are dynamic with an implicit time dependence. The softmax
greediness $\protect \beta$ and number of prospective teachers for social learners,
$\protect N_T$, are constant throughout each simulation.}
    \label{tab:modelParameters}
    \centering %\hspace{-3em}
    \begin{tabular}{cp{4.0in}p{1.25in}} \toprule

        Attribute & Description & Initial value \\ 

        \midrule  

        $s_i$  & Social learner trait: 1 if agent $i$ is social learner; 0 otherwise & 0
        or 1 equally likely \\

        $\bar\pi_{ib}$ & ``Ledger'': mean payoffs acquired via behavior $b$ by $i$ 
                       & $B$-vector of zeros \\

        $c_{ib}$ & Count of how many times agent $i$ performed $b$ 
              & $B$-vector of zeros \\

        $\pi_i$ & Net payoffs accumulated by $i$ within generation & 0.0 \\

        $\beta$ & Softmax greediness; $\uparrow=$more exploitation, $\downarrow=$more
                    exploration 
               & 1, \textbf{10}, 100 \\
        
        $N_T$    & Number of teachers to pool, from which best selected 
                 & 2, \textbf{5}, 10, 20  \\

        \bottomrule
    \end{tabular}
\end{table}



\subsection{Dynamics}

Model dynamics proceed by first initializing the environment and agents according
to the chosen parameter settings. % for the simulation.
Then, within each generation, agents select and perform behaviors, updating their estimated payoffs (and their probabilities of choosing each behavior) along the way.
Between generations, agents reproduce, teach social learners of the next generation, and die off. 
%Child agents then begin a new round of generational dynamics, followed by reproduction. 
This process continues until the population has evolved to fixation as either all social learners or all asocial learners, or until an upper limit of 20,000 
iterations has been reached. This process is visualized in
Figure~\ref{fig:schematic}.


\paragraph{Initialization}

The model is initialized with $N$ agents, all with zero observed mean payoffs, 
$\ledger = 0$, and zero counts of how many times
they have tried each behavior, $c_{ib} = 0$ (Figure~\ref{fig:schematic}A).
One of the behaviors is chosen at random to yield expected payoff $\pihigh$, with the other $B-1$ behaviors yielding
expected payoffs $\pilow$. Agents are independently randomly initialized with $s_i
\in 0,1$, so that 50\% of the initial population learn socially.


\paragraph{Within-generation dynamics}
% To guide behavior selection, agent $i$ counts how many times it
% performed each behavior $b$, denoted $c_{ib}$. Agents use this count to 
% update the mean payoff they have obtained from behavior $b$, denoted $\ledger$.
% $\ledger$ is initialized to 0 for all $b$ at model start for
% all agents (Figure~\ref{fig:schematic}A), and at 
% generation start for asocial learners. Social
% learning agents' $\ledger$ is initialized as that of its teacher, who is selected
% through performance-biased oblique learning; $c_ib$ is set to 1 for all social
% learners $i$ and behaviors $b$ (Figure~\ref{fig:schematic}C). Agent $i$'s
% accumulated payoffs from performing several behaviors over their lifetime of $L$
% time steps is denoted $\pi_{i}$. If an agent $i$ is a social learner, then we write
% $s_i = 1$, otherwise the agent is an asocial learner and $s_i = 0$.

Within each generation, all $N$ agents perform $L$ behaviors sequentially and
independently (Figure~\ref{fig:schematic}B).
Each agent selects one behavior on each step of its lifespan using softmax process
described above, updating the mean payoffs it has observed after each time step. Agent $i$ using behavior $b$ receives a payoff of 1 with probability $\pi_b$. 
%Agents probabilistically recieve a payoff of 0 or 1 depending on whether the bandit paid off. Behavior payoffs are drawn from a Bernoulli distribution with mean $\pi_b$, so $\pi_b$ is also the mean payoff from behavior $b$.  For concreteness we denote this probabilistic payoff $\bandit$. 
After performing behavior $b$, agent $i$ updates the
corresponding \emph{behavior count} by 1, $c_{ib} \leftarrow c_{ib} + 1$, and then
the expected payoffs calculated for that behavior are updated with
exponentially-weighted averaging
\begin{equation}
  \ledger \leftarrow \ledger + \frac{\bandit - \ledger}{c_{ib}},
\end{equation}
\noindent
where $\bandit$ is the actual payoff received by agent $i$ for behavior $b$ on the given time step. 

\paragraph{Intergenerational dynamics}
Between generations, agents first reproduce via asexual haploid reproduction, which determines the transmission of the social learning trait. Social learners then learn from the
previous generation, after which all agents from the
previous generation die off (Figure~\ref{fig:schematic}C). More specifically, this all happens as follows. 
$N$ reproducers are selected with replacement over $N$ independent draws, 
biased by performance:
\begin{equation}
  \Pr(\text{Agent $i$ is chosen to reproduce in one draw}) = \frac{\pi_i}{\sum_{i=1}^N \pi_i}.
\end{equation}
\noindent
A child inherits its parent's social learning trait $s_i$ without mutation.
A social learner child with $s_i = 1$ learns from a teacher from its parent's
generation, including possibly their parent (i.e., both vertical and oblique learning are possible). 
A child chooses its teacher by first randomly selecting $N_T$ prospective
teachers from the population, then selecting the one with
highest net payoffs $\pi_i$ as their teacher, with ties broken randomly \cm{this seems to contradict info under 2.2.2 Social learning section where there seems to be a probabilistic element weighted by relative payoff of teachers. I think it doesn't have to be described in both places.}. By first subsetting $N_T$ prospective teachers we represent the fact that access to the entire population is not generally guaranteed, though this type of algorithm yields qualitatively similar results to ones that do not first produce subsamples \cite{smaldino2019open}. 
Social learners adopt their chosen teacher's expected payoffs observations $\ledger$, \ps{I feel
like there should be some indication that the ledger is a vector rather than a scalar. Maybe put
it in bold or capitalize the $\Pi$? Using the overbar makes it look like a single average.}
\mt{The subscript $b$ makes it clear it's a vector over behaviors. Maybe we lose the bar,
or I may change the notation to at least approximately follow Q-learning notation.}
and set all $c_{ib} = 1$ so expected payoffs remain within $[0, 1]$. Setting $c_{ib}$ to 1 reflects the fact that the social learning is treating the teacher's information as a single observation with the associated uncertainty.   Asocial
learners ($s_i = 0$) are initialized with $c_{ib} = 0$ and $\ledger = 0$ 
(Figure~\ref{fig:schematic}C). \ps{How to account for division by zero?} \mt{Count increases
before average are taken, which I think is clear enough in paragraph \textbf{Within-generation
dynamics}.} The
newly initialized population then repeats the within-generation dynamics. 

After reproduction and die-off, the optimal behavior changes with probability
$u$. The new behavior is chosen from all other behaviors, with the 
current optimal behavior excluded from selection.

\paragraph{Stopping conditions} The evolutionary process continues until the
population reaches evolutionary fixation with repsect to social learning, where
$\sum_i s_i = 1$ or $\sum_i s_i = 0$, or until 20k iterations have run. 
It is rare for simulations not to reach fixation. We report how frequently
this happens in Table~\ref{tab:convergence}. 

\clearpage

\begin{figure}
  \caption{Agents are randomly initialized as social learners or not, with their
  payoff observations all initialized to zero (A). Then agents begin selecting
and performing behaviors and accumulating payoffs, which goes on for $L$
timesteps (B). After $L$ time steps, agents are selected to reproduce,
social learner children learn from a member of their parent's generation, and
the previous generation dies off (C). The simulation stops if children are all
social or asocial learners (i.e.\ the system reaches fixation), 
otherwise repeat another generation and evolution (3).}
  \label{fig:schematic}
  \centering
    \includegraphics[width=\textwidth]{Figures/IntraInterGenerationalDynamics.pdf}
\end{figure}


\subsection{Computational analyses}
\label{ssec:computationalAnalyses}

% We developed a series of computational
% analyses of the effect of uncertainty on social learning evolution by 
% systematically varying uncertainty parameters and observing how
% frequently model populations evolve to be social learners.  

To analyze the effect of the four principal uncertainty factors, we systematically
varied uncertainty values (Table~\ref{tab:modelParameters}) and observed how frequently social learning evolved across
1000 trial simulations for each combination of parameters tested. %We varied $u \in \{0.0, 0.1, \ldots, 1.0\}$; $\pilow \in \{0.1, 0.45, 0.8\}$; $B \in \{2, 4, 10\}$; and $L \in \{1,2,4,8\}$ for $B=2$ and $L \in \{1,B/2,B,2B\}$ for $B=4,10$.  
We observed three outcome measures, with $\meansl$ as the primary measure: the average value of $s_i$ over all agents and trials. To support our conclusions
based on $\meansl$, we also measured $\meanpi / L$, the average net  payoffs at simulation end across agents and trials, normalized by lifespan; 
and $\meanG$, the mean
number of generations to fixation (see Table~\ref{tab:outcomeVariables}). We analyze outcomes by plotting $\meansl$ on the y-axis and environmental variation is on x-axis since we
theoretically expect that $\meansl$ will decrease monotonically from 1 to 0 as $u$
increases. %Note that the hypothesis-testing concept of significance is meaningless here because we could make any small outcome difference ``significant'' by running more simulation trials.  We instead study the patterns of outcome variables over systematically varied uncertainty factor values. 

\begin{table}[h]
    \caption{Outcome variables.}
    \label{tab:outcomeVariables}
    \centering %\hspace{-3em}
    \begin{tabular}{cp{4.25in}p{0.85in}} \toprule

        Symbol & Description & Values \\ 

        \midrule  

        $\meansl$ & Mean social learning prevalence over agents and trials
                  & $\in [0.0, 1.0]$ \\

        $\meanpi / L$ & Mean payoffs accumulated in a generation normalized by
        lifespan & $\in [0.0, 1.0]$ \\

        $\meanG$ & Mean number of generations to convergence & 20k / 8 max. \\
        \bottomrule
    \end{tabular}
\end{table}


\subsubsection{Sensitivity analyses}

We performed sensitivity analyses to ensure that our main analysis is reasonably
robust to a range of auxiliary parameters. \ps{Say these are presented in the supplementary material?} First, we varied the population size, $N$, to explore whether smaller $N$ would show more drift due to finite population size effects. %, but  still generally support our main conclusions. 
Next, we varied the number of prospective teachers, $N_T \in \{2, 10, 20\}$, to supplement the main results that used $N_T = 5$. The number of prospective
teachers should not change whether social learning is optimal, but it may induce more drift since the benefit of social learning may
be more difficult to detect with fewer prosopective teachers. Finally, we varied the
softmax greediness parameter $\beta \in \{1, 100\}$ to supplement the main results
that used $\beta = 10$. We do not
expect agents with different $\beta$ to perform equally well 
individually, so certain $\beta$ values may themselves suppress social learning
by undermining individual learning. Nonetheless, our results
should be valid over some range of $\beta$. 


\subsubsection{Implementation}

Our model was implemented in the Julia programming language~\cite{Bezanson2017} 
using the Agents.jl agent-based modeling library~\cite{Datseris2022} and run
on the Sherlock supercomputing cluster at Stanford University. Model code and
data are publicly available on GitHub at \url{https://github.com/mt-digital/UncMod}.


\section{Analysis}

% To understand how different forms of uncertainty interact to affect the evolution of
% social learning, we measured how frequently social learning evolved across
% uncertainty parameters. We analyzed outcomes by plotting the mean observed social
% learning frequency, $\meansl$, with mean taken across all 1000 agents and 1000
% simulation trials for each uncertainty parameter setting at model fixation.
% % This is convenient because we are most certain about how $\meansl$ depends on $u$:
% % we expect $\meansl$ to decrease as $u$ increases since environmental variability
% % is well understood to cause socially-transmitted information to become outdated. 
% % To inspect patterns in $\meansl$ over all uncertainty parameters, 
% We analyze nine plots of how $\meansl$ (y-axis in each plot) changes over 
% environmental variability, $u$ (x-axis),
% in a $3\times3$ plot array (Figure~\ref{fig:mainResults}). 
% % All plots show how $\meansl$ changes (y-axis)
% % with environmental variability, $u$ (x-axis). 
% Selection set size, $B$, increases from left to right in the plot array (columns). 
% Payoff ambiguity increases as the non-optimal payoff, $\pilow$, increases from 
% top to bottom in the array (recall $\pihigh=0.9$ for all analyses).
% Effective lifespan, $L$, is indicated by line and marker colors (inset). 
% Several patterns in social learning prevalence emerged as 
% these uncertainty parameters were varied (Figure~\ref{fig:mainResults}). 


Our main results are illustrated by Figure~\ref{fig:mainResults}, which shows the proportion of simulation runs that fixated to 100\% social learners as a function of each of our four uncertainty measures.  First, we found that reliance on social learning monotonically decreased as temporal environmental variability, $u$, increased. When the environment was more likely to change between generations, information learned from the previous was less likely to be of value, decreasing selection on social learning. Past some threshold, social learning was not favored at all. However, the exact nature of the relationship between social learning and temporal environmental variability was tempered by our other three uncertainty parameters. 

Increasing the selection set size, $B$, favored the evolution of social learning. With only two behavioral choices ($B = 2$), a common assumption in many models, social learning is actively detrimental when the environment changes due to social learners being biased against the correct choice. When the selection set size increased, social learning was favored for two reasons. First, when the environment changed, bias against the new optimal was weaker with more behavioral options. Second and more importantly, when the environment remains constant between generations, the value of social learning increases with more behavioral options, because random search is less likely to yield useful information under a large search space. When the selection set size is very large, social learning is favored under quite high rates of temporal environmental variability. 

A shorter effective lifespan, $L$, also favored the evolution of social learning in most cases. When effective lifespans are long and there are many opportunities to gather information via individual learning, the value of social transmission is diminished. Given enough opportunities, the agents will all learn the optimal behavior eventually. Thus, under most conditions, longer effective lifespans led to a more narrow range of the parameters $u$ and $B$ under which social learning was favored. It is noteworthy that in many cases, a large increase in the selection regime for social learning could be observed when $L=1$ and by definition no individual learning occurred. 

Of the four types of uncertainty studied in this paper, payoff ambiguity had the most complex effect on the evolution of social learning. Recall that we operationalize payoff ambiguity with $\pilow$, the expected payoff for non-optimal behaviors (literally the probability that those behaviors yielded a payoff of 1). This was relative to $\pihigh = 0.9$, the expected payoff for the optimal behavior. When payoff ambiguity was low, non-optimal behaviors rarely paid off, so that exploration yielded reliable information and selection on learning strategies was  strong. When payoff ambiguity was very high ($\pilow = 0.8$), two things happened. Not only were agents likely to ascribe high value to non-optimal behaviors, but also selection on strategies that did reliably select the optimal behavior was relatively weak. This allowed for the effect of drift to become stronger, weakening selection in favor of social learning under small values of $u$ and weakening selection against social learning under high values of $u$. This effect was especially strong under other types of uncertainty: more temporal environmental variability, larger selection set sizes, and especially shorter effective lifespans---particularly when $L=1$ where no individual learning occurred. 

The effect of drift under short effective lifespans and high payoff ambiguity is powerful and complex. We explain how selection on social learning responds to these effects in more detail in the following section. 



% First, we confirmed existing theoretical predictions that increased $u$ 
% monotonically decreased $\meansl$ across all other uncertainty parameter values.
% The other uncertainty parameters changed the $u$ value at which $\meansl$
% began to decrease, and how rapidly $\meansl$ decreased over $u$.  For example,
% when payoff ambiguity and selection set size were both small ($\pilow = 0.1$
% and $B=2$), social learning evolved only when $u$ was small. 
% % These parameter settings present a relatively easy problem for individuals.
% % Furthermore, it is relatively costly for agents to be misled by outdated
% % social information in this case, especially for longer lifespans for finding
% % the optimal behavior (Figure~\ref{fig:mainResults}, upper left). 
% When $\pilow = 0.8$ and $B=2$, for exapmle, $\meansl$ decreased less rapdily
% over $u$ due to drift caused by weak selection due to little advantage for
% performing the optimal versus non-optimal behavior (see rows of
% Figure~\ref{fig:mainResults}). We analyzed several such patterns of social
% learning evolution and suppression across different uncertainty settings.

% Increased selection set size $B$ led nearly uniformly to more prevalent social
% learning, with all other uncertainty parameters held constant. This is because, first,
% it is more difficuilt to find the optimal behavior with a larger $B$.  Second, this
% effect is amplified because agents in a world with larger $B$ are more cognitively
% flexible compared to those in a smaller $B$ world.  When $B$ is larger, agents are
% relatively more likely to choose an alternative to their current known optimum.  To
% understand this, consider the case where a social learner child learns that behavior 1
% has an expected payoff of 0.8, and the rest have an expected payoff of 0, but the
% optimal behavior changes between generations. Assume the child tries behavior 1, but
% it pays off 0.  If $B=2$, then at the next time step, $\ledger =
% (0.4, 0.0)$. The probability the agent explores behavior 2 is now 0.02. However, if
% $B=10$ the agent has $\ledger = (0.4, 0.0, \ldots, 0.0)$, and the probability the agent
% explores one of the nine alternative behaviors increases to 0.14.  If the agent again
% tries behavior 1 and it pays 0, the probability of exploring alternatives with $B=2$
% is 0.21, but with $B=10$ the probability of exploring alternatives more greatly increases
% to 0.71. \mt{I double checked these calculations, but would appreciate if someone
%   triple checked it}. 
% This explanation does not apply when $L=1$, where individual learning does not occur. 

% Payoff ambiguity had a modest effect when $\pilow = 0.1$ increased to $\pilow =
% 0.45$, causing social learning to be favored across more values of $u$ (first two rows of
% Figure~\ref{fig:mainResults}).  This is because increased payoff ambiguity increases
% the difficulty, and reduces the overall benefit, of discerning which behavior is
% optimal.  When $\pilow = 0.8$ the
% $\meansl$ curves become smoother, indicating more evolutionary drift towards 
% possibly non-optimal fixations (bottom row of
% Figure~\ref{fig:mainResults}). For smaller values of $u$, this results in less
% frequent evolution of social learning for the same values of $u$ and $B$. But past
% the value of $u$ where $\meansl \approx 0.5$ this switches, and social learning evolves more
% frequently than for smaller $\pilow$. 
% % When $\pilow \to \pihigh$, agents 
% % accumulate increasingly more payoffs, whether they are social learners or not. 
% Greater payoff ambiguity means lower risk to try possibly outdated social
% information by reducing the penalty for performing non-optimal behaviors, leading
% to the observed drift in aggregated results. 

% We observed two distinct trends in the evolution of social learning as
% $L$ was varied.  First, when $\pilow$ was sufficiently small ($\pilow=0.1, 0.45$),
% we observed that shorter lifespan extended the evolution of social learning over more values of
% $u$, since payoff-biased social learning means teachers are reliable.
% When $\pilow=0.8$, shorter lifespans decreased $\meansl$ in some cases and
% increased $\meansl$ in other cases due to greater evolutionary drift. In
% this setting, many agents will obtain a payoff of 1 at each time step in their 
% lifetime, which, combined with finite population size, will make it more likely for 
% evolution to guide the population to non-optimal social/asocial learning stragegy.
% % In the first
% % case, $\meansl$ was reduced for $L=1$ for small values of $u$, when other $L > 1$
% % led to $\meansl \approx 1$. At larger $u$ , the $L=1$ case yields non-zero
% % $\meansl$, while for the other $L > 1$, $\meansl \approx 0$. 
% Smaller $L$ means agents end their lives more uncertain about which behavior was
% optimal, but payoff-biased teacher selection and learning can remedy this if
% payoff ambiguity is sufficiently small.
% % When $L$ is smaller, agents have fewer opportunities to learn through trial and
% % error, so it is more difficult for them to discern which strategy is optimal, social
% % or asocial. 

\begin{figure}
  \caption{Social learning prevalence (y-axes) monotonically decreases as 
  environmental variabilty, $u$, increases (x-axes) in most uncertainty contexts. 
  Other uncertainty values $\pilow$ (rows), $B$ (columns), and $L$ (keys)
  shift and flatten the decrease from all-social-learner populations to all-asocial 
  populations.}
  \label{fig:mainResults}
  \centering
    \includegraphics[width=\textwidth]{{Figures/supplement/nagents=1000/mainResultsPlots.pdf}}
\end{figure}

\subsection{The relative benefit of social learning and the presence of evolutionary drift}

% To explain the evolution of social learning we implicitly assumed above that, first,
% the relative benefit of having the social learning trait is essential to its
% evolution; and, second, we assumed that values of $\meansl \neq 0,1$ indicate
% evolutionary drift---but do our data support these assumptions?  
%Indeed, w
The effect of drift on the evolution of social learning %evolution and evolutionary drift 
depended on the extent to which the social learning trait provided agents with a consistent benefit. Drift infuses randomness into natural selection, which can lead a population under a consistent but weak selection pressure to take longer to reach fixation \cite{plutynski2007drift}. Drift is maximal when social and asocial learning are equally beneficial and fixation takes longer to achieve. We therefore measured drift by the average number of generations to fixation, denoted $\langle G \rangle$, where fixation means that $\sum_i s_i$ is equal to either zero or $N$. %Indeed, social learning evolution and drift are reflected in the relative benefit of social learning to asocial learning.  


First, we confirmed that social learning evolves when the expected payoffs to social
learners exceed those of asocial learners, which we write $\meansoc > \meanasoc$.
In the case of $L=1$ we can calculate $\meanasoc$ directly: it is just the expected
payoff across all behaviors. For all other cases, we calculate expected social and asocial payoffs by respectively setting
$\sum_i s_i = N$ or $\sum_i s_i = 0$ at model initialization. These stay constant since we do not allow for mutation. These are the payoffs to a homogeneous population of either all social learners or all asocial learners.  Figure~\ref{fig:payoffs} shows these expected payoffs, normalized by effective lifespan $L$), as well as the observed average payoffs in our simulations. \ps{Is this right? I'm having trouble understanding what the solid lines in Figs 3 and 5 are. I'm also debating the wisdom of separating these figures. Maybe we put the 3x3 back in for Fig 3?}
In general, we observed that social learning evolved in our simulations when the expected payoffs exceeded expected individual-learner
payoffs (Figure~\ref{fig:payoffs}). 
% However, we also found that populations of initially all social learners performed worse
% in many uncertainty contexts than either the actual payoffs accumulated by 
% model agents, and lower than even the expected individual-level payoffs,
% even though social learning evolved in many of the same contexts in our model,
% especially when $\pilow = 0.8$ 
% (Figure~\ref{fig:fullMeanPrevNetPayoffs}, bottom row). \ps{What is the point of this last finding? I'm having trouble figuring out what all this has to do with drift.}

% \begin{figure}
%   \caption{Expected payoff rates for homogeneous populations of social or asocial learners. Dashed lines with no markers are expected payoff rates for a population of individual learners. Dashed lines with diamond markers are expected payoff rates to a population of social learners. Solid lines with circle markers are the actual average payoff rates for agents in our evolutionary simulations.  
% %  Comparison of expected payoffs from our computational anaysis (solid     lines with circles), expected individual payoffs with no social learning     (dashes without markers), and expected payoffs for all-social learner     populations. 
% Only four plots are shown to enhance detail; see supplement for
%     five additional plots.
% } 
%   \label{fig:payoffs}
% \centering
%     \includegraphics[width=0.85\textwidth]{Figures/meanNetPayoffs.pdf}
% \end{figure}

\begin{figure}
  \caption{Expected payoff rates for homogeneous populations of social or asocial learners. Dashed lines with no markers are expected payoff rates for a population of individual learners. Dashed lines with diamond markers are expected payoff rates to a population of social learners. Solid lines with circle markers are the actual average payoff rates for agents in our evolutionary simulations.  When $\pilow = 0.8$, all-social learner populations underperform
    since social learners are not subject to an initial evolutionary bottleneck
    due to the presence of asocial learners, and behavioral misinformation
    is allowed to circulate more freely than in the base case tested by 
    our model with an initially even distribution of social and asocial learners.
    \mt{Correct or nah?}
}
  \label{fig:payoffs}
  \centering
    \includegraphics[width=\textwidth]{Figures/supplement/fullMeanPrevNetPayoffs.pdf}
\end{figure}

Figure~\ref{fig:steps} shows the average time to fixation, $\meanG$, for all our our uncertainty parameters. We confirmed that drift increased when $\meansl$ was furthest from either 0 or 1 (that is, when fixation to either extreme was possible), 
and when the payoff ambiguity $\pilow$ was increased (Figure~\ref{fig:steps}). 
%We measured drift by the average number of generations to fixation, $\meanG$. Recall fixation is defined as the population becoming homogenous, composed of all social or all asocial learners. 
$\meanG$ peaks around the values of $u$ 
when $\meansoc \approx \meanasoc$, which led $\meansl$ to transition from 1 to 0.
In some cases, especially when $\pilow=0.8$,
there is no distinct peak in $\meanG$ across $B$ and $L$ settings, 
indicating little difference in task difficulty across a range of uncertainty
parameter settings (Figure~\ref{fig:steps}, bottom row).


\begin{figure}
  \caption{Average number of generations ($\meanG$, y-axes) to fixation . 
    $\meanG$ increases and peaks around values of $u$ (x-axes) where
  $\meansoc \approx \meanasoc$. Note the y-axis ticks vary between plots,
indicating different overall time to fixation for different $(\pilow, B)$
pairs. Only extremal tested values of $L$ shown for clarity.} 
  \label{fig:steps}
\centering
    \includegraphics[width=\textwidth]{Figures/stepResultsPlots.pdf}
\end{figure}


\section{Discussion}

By disambiguating various formalizations of uncertainty in a single computational model, we have developed a more nuanced theoretical understanding of how uncertainty affects the evolution of social learning.
%We reviewed and distilled several empirical and theoretical models in the literature along four uncertainty dimensions: temporal environmental uncertainty, selection set size, ambiguous payoffs, and effective lifespan.  
We reproduced the well-known results that the uncertainty derived from a temporally variable environment can favor the evolution of social learning up the point where environmental change is simply too rapid for intergenerational transmission to be of value. Importantly, we also showed that this relationship is affected by other sources of uncertainty. 
%Our model reproduced classic predictions that social learning can yield higher payoffs than individual learning when uncertainty is sufficiently limited. 
We found that larger selection sets, shorter effective lifespans, and increased payoff ambiguity could all favor the evolution of social learning. However, these effects were not always straightforward. 
Increased payoff ambiguity and decreased effective lifespan afforded a greater role for drift, which is essentially
evolutionary uncertainty in a finite-size population. When the ability to learn individually is also fraught with uncertainty, selection either for or against social learning may be substantially weakened. 

Our model helps to demonstrate that social learning can act as a scaffold for individual learning---despite the framing of many other papers, they are not opposites. 
We endowed agents with a biologically-plausible individual learning mechanism, softmax search. This allowed for highly successful individual learning that helped agents recover from the potential cost of receiving outdated information. This in turn enabled the evolution of social learning 
even when social information was likely to be outdated. 
Detailed theoretical models like this are likely to be critical for understanding how humans might adapt to an uncertain and rapidly changing world.
Such understanding could help suggest plausibly beneficial interventions to mitigate existential threats~\cite{Moya2020,Jones2021}, especially in
the most vulnerable communities~\cite{McNamara2020}, and to capitalize on new behavioral opportunities such as transitioning to clean energy use and
production~\cite{NatureEnergyEditorialPromisesPremises2018,Brisbois2022}.

Our model necessarily made simplifying assumptions. These choices were judiciously made to address the main question of how uncertainty affects the evolution of social learning in general; however there exist alternative empirically-valid choices we could have made, the future exploration of which will be important to the development of a more nuanced theory of social learning.  % that may not always hold in more specific situations, though they are empirically justified to be general across taxa. 
For example, we considered only success-biased
learning, although conformity or other context biases may sometimes be the social learning mechanism~\cite{BoydRicherson1985,Muthukrishna2016a,Smaldino2018b}.  Conformity may lead to more drift
overall, since success-biased teacher selection, which we assumed, maximizes the potential benefit to social learners. We also assumed that the number of behaviors and
their payoffs were constant within a given simulation, but this fails to account for evolutionary feedback which
creates new behavioral opportunities as time progresses, e.g.\ via niche
construction~\cite{Smaldino2012a,Heras-Escribano2020} or cumulative cultural evolution
supported by dynamic network structure~\cite{Smolla2019,Derex2020}.  Group structure
and processes such as homophily and in-group bias/out-group aversion could inhibit the
evolution of social learning since successful outgroup teachers could be cut off from
in-group learners~\cite{Golub2012}. We assumed agents choose behaviors via softmax
search, but this is an underpowered algorithm compared to the real human individual learning~\cite{Schulz2020a,Wu2022}.  More powerful individual learning could further
support social learning.  These considerations reveal new opportunities to enhance theoretical nuance by adjusting or extending the present model for other contexts. 


%\subsection{Conclusion}

%We found that the 
The evolution of social learning is a complex phenomenon, dependent on many interrelated factors. Although social learning is widely studied, few studies have previously examined how various environmental variables contributing to uncertainty interact. 
By carefully identifying and operationalizing common theoretical assumptions about contextual uncertainty in social learning models, we developed a more systematic
understanding of which uncertainty factors interact to determine whether social
learning evolves. By explicitly modeling a key individual-level learning mechanism
shared across taxa, namely the ability to adjust behavior to uncertainty and new
information, we saw that social learning could evolve even if social learning
regularly provides outdated information. This work most directly informs our current understanding of the evolution of social learning, but also has broader significance for
understanding problem solving under uncertainty. \ps{What is this significance? Can't just leave that dangling. I also cut the bit about what comes next. No need for spoilers.} 
%Our model and its software implementation were designed to be modular and extensible.  Indeed, we plan to extend this model to further develop a more detailed theoretical understanding of the evolution of social learning; we hope others will, too.


\bibliographystyle{apacite}
% \bibliography{/Users/mt/workspace/Writing/library.bib}
\bibliography{this.bib}


%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
\pagebreak
\begin{center}
  \textbf{\Large \textsf{Supplement}}
\end{center}
%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%
\setcounter{equation}{1}
\setcounter{figure}{0}
\setcounter{section}{0}
\setcounter{table}{0}
\setcounter{page}{1}
\makeatletter
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thepage}{S\arabic{page}}
% \renewcommand{\bibnumfmt}[1]{[S#1]}
% \renewcommand{\citenumfont}[1]{S#1}
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%




% \section{Additional main figure: Full net payoff comparison for all nine uncertainty conditions} 
% \ps{This should be part of the supplement. Also, all supplementary figures and tables should be preceded by ``S".}
% In the main text we showed a $2\times2$ array of plots comparing the observed
% mean net payoffs obtained by agents in our simulations, and in two auxiliary
% sets of simulations that set all agents to either have the social learning
% trait or not, which remained the case for the entire simulation since there
% are no mutations in this model (Figure~\ref{fig:payoffs}). Here we show the full $3\times3$ array of
% all $(\pilow, B)$ combinations shown for the main results. We see that
% populations of all social learners especially underperform initially mixed
% populations that evolve to be social learners 
% (Figure~\ref{fig:fullMeanPrevNetPayoffs}, bottom row). This highlights the
% importance of diversity for behavioral optimization, even if it is transient.


% \newpage



In this Supplement we support our model conclusions with auxiliary data
showing, first, sufficient model convergence and, second, that our model
outcomes are stable over various settings of the three free auxiliary model
parameters: the number of agents ($N$), the number of
prospective teachers pooled by social learner children for social learning
($N_T$), and the softmax behavior selection greediness parameter ($\beta$).
The main source of minor deviations from the main results was greater drift
due to (1) finite population size effects, with greater drift for smaller $N$;
(2) lower quality of socially-learned information agents can access with fewer
prospective teachers; and (3) lower quality social information when $\beta$
was small since teacher agents would have explored non-optimal behaviors more
frequently, so their observed payoffs would have less probability weight in
the optimal payoffs on average. We give details below of model convergence, and
outcomes as we varied the three auxiliary parameters $N$, $N_T$, and $\beta$.


\section{Convergence information}

Model populations reached fixation within few to 140 generations on
average (Figure~\ref{fig:steps}).
Note 140 generations is equivalent to 2800 time steps. We set the maximum 
number of iterations globally to $20~000$, which is 1000 generations when
$L=20$. Although we can be relatively sure that this maximum number of 
generations is rarely reached based on our main text analysis of $\meanG$,
we additionally tabulated the number of simulations that did not converge to
fixation
within this step limit. We found that 0.1\% of simulations did not converge
when $B=2$, 0.2\% did not converge when $B=4$, and 2.0\% did not converge
when $B=10$ (Table~\ref{tab:convergence}). When a trial did not converge we
still included that trial's $\meansl$ value in the average across trials,
but for these $0 < \meansl < 1$.

\begin{table}[h] \caption{Maximum number of iterations = 20000.} \label{tab:convergence} \centering
  \begin{tabular}{cccc} 
    \toprule $B$ & \# not at fixation (out of 132k) & \% not fixated \\ 
    \midrule  2  & 0  & 0.0 \% \\ 
              4  & 0  & 0.0 \% \\ 
              10 & 20 & 0.02 \% \\ 
    \bottomrule \end{tabular} 
\end{table}



\newpage

\section{Population size sensitivty analysis}

Drift was greater for smaller populations sizes, especially when $\pilow=0.8$, but 
the main patterns generally remain for $N=50$, $N=100$, and $N=200$ (recall
$N=1000$ tested in main analysis). Drift is also more pronounced for smaller $N$
for shorter lifespans, especially $L=1$. When $L=1$ and $N=50$ , the S-shaped
curve of $\meansl$ over $u$ becomes more linear with increasing $B$, 
with $\meansl$ values pulled towards maximal drift, $\meansl \to 0.5$ (Figure~\ref{fig:populationSensitivity}a,
purple curves). With
$N=50$, all $\meansl$ over $u$ curves are flattened with less sharp transitions
from $\meansl = 1$ for lesser $u$ to $\meansl = 0$ for greater $u$. Despite
these finite-population effects, we still see the inhibition of social learning
as $u$ increases, more social learning across $u$ for larger $B$, and the
same complex drift effects for combinations of $\pilow$ and $L$ that interact
with $u$ and $B$ settings.

\clearpage

\begin{figure}
  \centering
  % \addtocounter{figure}{-1}
  \caption{
	Sensitivity analysis of the main results for different population
	sizes, $N=50,200,1000$. Recall $N=100$ was used to generate main 
	text results.
  }
  \label{fig:populationSensitivity}
  \begin{subfigure}{\textwidth}
	\caption{$N=50$}
	\includegraphics[width=\textwidth]{Figures/supplement/nagents=50/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}

\begin{figure}
  \ContinuedFloat
	\begin{subfigure}{\textwidth}
	  \caption{$N=100$}
	  \includegraphics[width=\textwidth]{Figures/mainResultsPlots.pdf}
	\end{subfigure}
\end{figure}
	
\begin{figure}
  \ContinuedFloat
	\begin{subfigure}{\textwidth}
	  \caption{$N=200$}
	  \includegraphics[width=\textwidth]{Figures/supplement/nagents=200/mainResultsPlots.pdf}
	\end{subfigure}
\end{figure}


\clearpage

\section{Number of prospective teachers sensitivty analysis}

We found that the number of prospectve teachers had little effect on $\meansl$
over $u$. There was slightly more drift when $N_T = 2$ compared to our 
main text analysis, slightly less drift than our main analysis when $N_T = 20$, 
and no obvious difference between $N_T = 10$ tested here and our main results
with $N_T = 5$. When $N_T = 2$, increased drift is most notable in the
$\meansl$ curves when $\pilow=0.8$ (Figure~\ref{fig:nteachersSensitivity}a, 
bottom row). The transition from $\meansl = 1$ to $\meansl = 0$ is less sharp
across $L$ values, with social learning evolution being suppressed beginning
at smaller values of $u$. By contrast, when $N_T = 20$, transitions from 
$\meansl = 1$ to $\meansl = 0$ are sharper across $L$ when $\pilow = 0.8$
(Figure~\ref{fig:nteachersSensitivity}c, bottom row). Otherwise, the main 
results were reproduced across all tested values $N_T=2,5,10,20$.

\clearpage


\vspace{-3em}
\begin{figure}
  \centering
  % \addtocounter{figure}{-1}
  \caption{Number of prospective teachers sensitivity analysis for $N_T=2,10,20$. Recall
  $N_T=5$ was used to generate main text results.}
  \label{fig:nteachersSensitivity}
  \vspace{2em}
  \begin{subfigure}{\textwidth}
	\caption{$N_T = 2$}
	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=2/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}
\newpage
\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{\textwidth}
	\caption{$N_T = 10$}
	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=10/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}
\newpage
\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{\textwidth}
	\caption{$N_T = 20$}
	\includegraphics[width=\textwidth]{Figures/supplement/nteachers=20/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}

\clearpage


\section{Softmax parameter sensitivity analysis} 

We tested two additional settings of the softmax behavior selection greediness parameter,
$\beta=1,100$, which reproduced qualitative patterns in the evolution of social learning
observed in the main text where we used $\beta=10$.  
Softmax greediness is achieved formally by increasing the
probability mass for selecting behaviors that have paid off more frequently over that agent's
life history. In other words, greater $\beta$ increases the probabilty that the optimal
observed behavior is chosen over all the rest. If $\beta$ is too small, agents will fail to
fully exploit their knowledge about which behavior is optimal because they too frequently
explore less profitable alternatives.  If $\beta$ is too great the agents may prematurely
settle on a sub-optimal behavior because it paid off first.  In a fuller evolutionary
exploration of model parameters one might allow $\beta$ to co-evolve, through
mutation and selection, with the social learner trait.  
However, our sensitivity analysis suggests this would be unnecessary 
since our main conclusions of how social learning evolves under uncertainty remain unchanged for different
$\beta$ over three orders of magnitude.

First, when $\beta=1$, most general trends are preserved, but in many cases the evolution
of social learning is suppressed or drift dominates due to 
due to the overall poor quality of information acquired through softmax search-based
individual learning. This increased drift is especially pronounced 
when $\pilow=0.8$ since sub-optimal behaviors often pay off and $\beta=1$ is
not aggressive enough to efficiently detect and exploit the optimal 
behavior (Figure~\ref{fig:softmaxSensitivity}a, bottom row).
Similarly, when $\beta = 1$, social learning is suppressed at much smaller values
of $u$ for longer lifespans, $L$, due to maximal excessive exploration of non-optimal
behaviors under this setting (Figure~\ref{fig:softmaxSensitivity}a, columns 
for $B$ and inset for $L$).

With $\beta=100$, the changes in outcomes were minimal compared
to setting $\beta=1$ (Figure~\ref{fig:softmaxSensitivity}b). 
In some cases, such as $(\pilow=0.1, B=10)$ 
and $(\pilow=0.45, B=2)$,
there appears to be more drift across all $L$ around the transition
point when $\meansl = 1$ goes to 0 as $u$ increases. However it appears
that there is more drift at the transition for $\beta=10$ for
$(\pilow=0.45, B=10)$. 


\vspace{-3em} \begin{figure} %\addtocounter{figure}{-1} 
  \centering
  \caption{Sensitivity analysis of the main results for the softmax parameter $\beta = 100$ and
  % \addtocounter{figure}{-1}
  $\beta=1$. Recall the main results were obtained with $\beta = 10$.}
  \label{fig:softmaxSensitivity} \vspace{2em}
  \begin{subfigure}{\textwidth}
	\caption{$\beta = 1$}
	\includegraphics[width=\textwidth]{Figures/supplement/sensitivity_tau=1.0/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}
\newpage
\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{\textwidth}
	\caption{$\beta = 100$}
	\includegraphics[width=\textwidth]{Figures/supplement/sensitivity_tau=0.01/mainResultsPlots.pdf}
  \end{subfigure}
\end{figure}



\end{document}
